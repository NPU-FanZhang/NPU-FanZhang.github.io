[{"id":"696c711dc425c21ecfe6691bc40887b7","title":"JUC","content":"1. JUC 概述所谓JUC是 java.util.concurrent 工具包的简称，这是一个处理线程的工具包，可以实现程序的多线程高并发。\n多线程编程的一般步骤:\n\n创建资源类,在资源类创建属性和操作方法。\n在资源类操作方法:判断、操作、通知\n创建多个线程，调用资源类的操作方法。\n防止虚拟唤醒问题\n\n多线程锁的演变\n\n无锁：多线程抢夺资源\nsynchronized和ReentrantLock，都是独占，每次只可以一个操作，不能共享\nReentrantReadWriteLock，读读可以共享，提升性能，但是不能多人写。缺点：造成死锁（一直读，不能写），读进程不能写，写进程可以读。\n写锁降级为读锁（一般等级写锁高于读锁）\n\na. 进程和线程1. 进程（Process）\n计算机中的程序关于某数据集合上的一次运行活动\n进程是线程的容器\n程序是指令、数据及其组织形式的描述，进程是程序的实体\n系统进行资源分配和调度的基本单位，是操作系统结构的基础\n\n2. 线程（Thread）\n操作系统能够进行运算调度的最小单位\n被包含在进程之中，是进程中的实际运作单位\n一条线程指的是进程中一个单一顺序的控制流\n\n通俗易懂理解\n\n进程代表一个程序的执行，而线程是程序中的某个单元执行流\n程序一旦运行就是进程；进程是资源分配的最小单位而线程是程序执行的最小单位。一个进程中可以并发多个线程，每条线程并行执行不同的任务\n\nb. 线程的状态通过线程枚举类的状态可以看到,线程的状态有: 创建(new)、就绪(runnable)、运行(running)、阻塞(blocked)、time waiting、waiting、消亡（dead）\n\n\n\n\nc. 串行、并行和并发串行(serial):表示所有任务都一一按先后顺序进行并行(parallel):同时取得多个任务，并同时去执行所取得的这些任务并发(concurrent):多个程序可以同时运行、也可以是多进程同时运行或多指令可以同时运行,但并发不一定并行，也可以说并发事件之间不一定要同一时刻发生。 \n通俗易懂的理解  \n\n并发是同一时刻多个线程在访问同一个资源\n并行是多项工作一起执行，之后再汇总\n\n举例比如：多个人访问同个网址，为多个线程访问一个网址，多对一此为并发。而并行是多个工作一起执行，每个工作都是一个资源一个线程。之后合并起来就是一个并行工作\n结合以上的搭配可以产生多路复用或异步的方式\n实际上，对于单核心 CPU 来说，同一时刻只能运行一个线程。所以，这里的”同时运行”表示的不是真的同一时刻有多个线程运行的现象，这是并行的概念，而是提供一种功能让用户看来多个程序同时运行起来了，但实际上这些程序中的进程不是一直霸占 CPU 的，而是执行一会停一会\nd. wait和sleep的区别\nwait: Object 的方法，会释放锁，调用它的前提是当前线程占有锁(即代码要在 synchronized 中)\nsleep: Thread 的静态方法，任何对象实例都能调用。不会释放锁，也不需要占用锁\n\n相同点 : 都可以被 interrupted 方法中断,在哪里等待,就在哪里恢复\ne. 管程管程在java中是锁，在操作系统中是monitor监视器\n代表一种同步机制，同一时间内只能有一个线程访问且被保护数据\n比如jvm的同步基于进入和退出，是管程对象实现\n\n每个对象都有一个monitor管程对象，都会随着java的对象进行创建和销毁\n管程对象对临界区加锁和解锁\n\n大意就是进加锁，退是解锁，通过管程对象管理。\n2. Synchronized造成线程安全主要原因是因为数据共享，为了解决这种情况，引出 synchronized，它是 Java 中的关键字，是一种同步锁（对方法或者代码块中存在共享数据的操作）。\n修饰对象的方式\n\n修饰代码块\n修饰方法\n修饰静态方法\n修饰一个类\n\n一个简单的例子\n123456789101112131415161718192021222324public class sync &#123;    public static void main(String[] args) &#123;        Ticket ticket = new Ticket();        /*2个售票员售出30张票*/        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 40; i++) &#123;                ticket.sale();            &#125;        &#125;, &quot;seller1&quot;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 40; i++) &#123;                ticket.sale();            &#125;        &#125;, &quot;seller2&quot;).start();    &#125;    static class Ticket &#123;        public int number = 30;        public synchronized void sale() &#123;            if (number &gt; 0)                System.out.println(Thread.currentThread().getName() + &quot;买了1张票&quot; + &quot;,剩余&quot; + (--number) + &quot;张票&quot;);            else System.out.println(Thread.currentThread().getName() + &quot;没买到&quot;);        &#125;    &#125;&#125;\n\n123456789101112131415161718seller1买了1张票,剩余29张票seller1买了1张票,剩余28张票seller1买了1张票,剩余27张票seller1买了1张票,剩余26张票...seller1买了1张票,剩余2张票seller1买了1张票,剩余1张票seller1买了1张票,剩余0张票// synchronized不能响应中断,所以访问共享资源时,会在一个线程执行完再执行下一个seller1没买到seller1没买到...seller3没买到seller3没买到seller3没买到...seller2没买到seller2没买到\n\n在实现**sale()**方法时,加上synchronized关键字,不能响应中断,当第一个线程进入后,访问共享资源时,只有当线程结束才会释放；不加synchronized关键字，两个线程会同时进入这个方法。\n3. 创建线程的方式实际上只有一种方式,就是构造Thread类,其他的是衍生出来的。\n构造Thread类，又衍生出两种方式，一是继承Thread类，二是实现Runnable接口，但无论是那种方式，最终也要创建Thread类的对象或其子类对象。\na. 继承 Thread 类12345678910111213141516class MyThread extends Thread &#123;    @Override    public void run() &#123;        for (int i = 0; i &lt; 10; i++) &#123;            System.out.println(Thread.currentThread().getName() + &quot;----&quot; + i);        &#125;    &#125;&#125;public class ThreadDemo &#123;    public static void main(String[] args) &#123;        System.out.println(Thread.currentThread().getName() + &quot; `= main&quot;);        MyThread myThread = new MyThread();        myThread.start();    &#125;&#125;\n\n\n\nb. 实现 Runnable接口123456789101112public class InheritedInterface &#123;    public static class MyThread implements Runnable &#123;        @Override        public void run() &#123;            System.out.println(&quot;--- in Runnable ---&quot;);        &#125;    &#125;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        Thread t1 = new Thread(new MyThread());        t1.start();    &#125;&#125;\n\nc. 实现 Callable 接口1234567891011121314151617class MyThread implements Callable&lt;String&gt; &#123;    @Override    public String call() throws Exception &#123;        System.out.println(Thread.currentThread().getName());        return &quot;hello world&quot;;    &#125;&#125;public class ThreadDemo &#123;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        FutureTask futureTask = new FutureTask(new MyThread());        Thread thread = new Thread(futureTask);        thread.start();        // 获取返回值        System.out.println(futureTask.get());    &#125;&#125;\n\n\n\nd. 使用线程池123456789101112131415// 一池多线程ExecutorService threadPool1 = Executors.newFixedThreadPool(3);  // 实际生产中,自定义线程池来进行线程创建try &#123;    /*模拟5个线程放入大小为3的线程池*/    for (int i = 0; i &lt; 10; i++) &#123;        threadPool1.execute(() -&gt; &#123;            System.out.println(Thread.currentThread().getName() + &quot; 办理业务&quot;);        &#125;);    &#125;&#125; catch (Exception e) &#123;    e.printStackTrace();&#125; finally &#123;    // 关闭线程池    threadPool1.shutdown();&#125;\n\n\n\n* Runbale与Callable的区别12345678910111213public static class MyThread implements Runnable&#123;    @Override    public void run() &#123;            &#125;&#125;private static class MyThreadCall implements Callable&#123;    @Override    public Object call() throws Exception &#123;        return null;    &#125;&#125;\n\n\nCallable实现的方法是call(),Runnable实现的方法是run().\nCallable的任务执行后有返回值，而Runnable的任务没有返回值\ncall方法可以抛出异常，run方法不可以\n运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。\n\n4. Lock 接口12345678public interface Lock &#123;\tvoid lock();\tvoid lockInterruptibly() throws InterruptedException;\tboolean tryLock();\tboolean tryLock(long time, TimeUnit unit) throws InterruptedException;\tvoid unlock();\tCondition newCondition();&#125;\n\nLock接口为锁和等待条件提供一个框架的接口和类，不同于内置同步和监视器。\nLock是接口，可通过实现类同步访问，多个接口实现类：可重入锁等。\n\nReentrantLock(可重入锁) 是唯一实现了 Lock 接口的类，并且 ReentrantLock 提供了更多的方法\n\nReentrantReadWriteLock 里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和 writeLock()用来获取读锁和写锁writeLock();来获取读锁readLock();获取写锁\n\n\n一个Lock锁的例子\n12345678910111213141516171819202122232425262728293031323334353637383940public class sync &#123;    public static void main(String[] args) &#123;        Ticket ticket = new Ticket();        /*3个售票员售出30张票*/        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 40; i++) &#123;                ticket.sale();            &#125;        &#125;, &quot;seller1&quot;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 40; i++) &#123;                ticket.sale();            &#125;        &#125;, &quot;seller2&quot;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 40; i++) &#123;                ticket.sale();            &#125;        &#125;, &quot;seller3&quot;).start();    &#125;    static class Ticket &#123;        public int number = 30;        private final ReentrantLock lock = new ReentrantLock();        public void sale() &#123;            // 加锁            lock.lock();            try &#123;                if (number &gt; 0)                    System.out.println(Thread.currentThread().getName() + &quot;买了1张票&quot; + &quot;,剩余&quot; + (--number) + &quot;张票&quot;);                else System.out.println(Thread.currentThread().getName() + &quot;没买到&quot;);            &#125; finally &#123;                // 解锁 为了避免解锁前出现异常而导致没有解锁,需放入finally中                lock.unlock();            &#125;        &#125;    &#125;&#125;\n\n12345678910111213141516171819seller1买了1张票,剩余29张票seller1买了1张票,剩余28张票seller1买了1张票,剩余27张票seller1买了1张票,剩余26张票seller1买了1张票,剩余25张票seller1买了1张票,剩余24张票...// lock可以响应中断,所以也有其他线程能买到票seller3买了1张票,剩余6张票seller3买了1张票,剩余5张票seller3买了1张票,剩余4张票seller3买了1张票,剩余3张票seller3买了1张票,剩余2张票seller3买了1张票,剩余1张票seller3买了1张票,剩余0张票seller3没买到seller3没买到seller3没买到seller3没买到...\n\n\n\nLock与synchronized的区别\n\nlock不是Java语言内置的,synchronized是Java语言的关键字,因此是内置特性。\nlock和synchronized的很大不同时，synchronized是自动的上锁和释放锁，而lock需要用户去手动释放锁，否则可能会死锁。\n发生异常时,synchronized会自动释放锁,而lock不会，所以unlock解锁需要放在try&#x2F;finally的finally语句块中。\nlock可以让等待锁的线程响应中断,而synchronized不行,线程会一直等待下去。\nlock可以知道有没有成功获得锁,而synchronized不行。\n资源竞争不激烈时,两者性能差不多;资源竞争激烈时,lock性能高很多。\n\n5. 线程间通信线程间通信的模型有两种：共享内存和消息传递\na. synchronized实现线程同步一个线程synchronized实现通信的例子\n实现一个由两个线程操作同一个变量,交换进行01切换的类\n12345678910111213141516171819202122232425262728293031323334353637383940414243public class communication &#123;    public static void main(String[] args) &#123;        Share share = new Share();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 3; i++) &#123;                try &#123;                    share.add();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;, &quot;AA&quot;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 3; i++) &#123;                try &#123;                    share.minus();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;, &quot;BB&quot;).start();    &#125;    /*实现一个由两个线程操作同一个变量,进行01切换的类*/    static class Share &#123;        private int number = 0;        public synchronized void add() throws InterruptedException &#123;            // 不是0时进行等待            if (number != 0) this.wait();            number++;            System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number);            // 通知其他线程            this.notifyAll();        &#125;        public synchronized void minus() throws InterruptedException &#123;            if (number != 1) this.wait();            number--;            System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number);            // 通知其他线程            this.notifyAll();        &#125;    &#125;&#125;\n\n123456AA::1BB::0AA::1BB::0AA::1BB::0\n\n如果在方法中不加synchronized,会报错java.lang.IllegalMonitorStateException\njava.lang.IllegalMonitorStateException是在调用object的wait和notify，notifyAll方法的时候可能会出现的异常。 \n在调用上述三个方法的时候，线程必须获得该对象的对象级别锁，换句话说，出现这个异常的原因是因为，调用wait和notify，notifyAll的对象没有在同步方法（synchronized修饰的方法）或者同步代码块（synchronized（x）{}）中。\nwait()和notify()方法的调用必须具有内置锁 synchronized(this) 的代码块内或同步方法才能调用，否则就会报该错误。\n如果用了显式锁 Lock 就不要用 wait() 和 notify() 了，它们是两套加锁机制，不能混着用的。\n* 虚假唤醒问题如果再添加两个线程去操作变量,可能会造成虚假唤醒问题。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static void main(String[] args) &#123;    Share share = new Share();    new Thread(() -&gt; &#123;        for (int i = 0; i &lt; 3; i++) &#123;            try &#123;                share.add();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;, &quot;AA&quot;).start();    new Thread(() -&gt; &#123;        for (int i = 0; i &lt; 3; i++) &#123;            try &#123;                share.minus();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;, &quot;BB&quot;).start();    new Thread(() -&gt; &#123;        for (int i = 0; i &lt; 3; i++) &#123;            try &#123;                share.add();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;, &quot;CC&quot;).start();    new Thread(() -&gt; &#123;        for (int i = 0; i &lt; 3; i++) &#123;            try &#123;                share.minus();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;, &quot;DD&quot;).start();&#125;AA::1DD::0CC::1BB::0CC::1BB::0CC::1BB::0DD::-1  // 出现了-1AA::0AA::1DD::0\n\n如果一个线程执行完毕后，通知其他线程，该线程又进入等待睡眠，可能会因为某些原因被唤醒后，if结构的语句就不会判断了，一直往下执行，所以需要将if换成while结构，每次都判断。因为wait在哪里睡眠就在哪里被唤醒，结果被某个异常唤醒了后回不去了，if结构不会在判断了，需要更改为while\n123while(number != 0) &#123; //判断number值是否是0，如果不是0，等待    this.wait(); //在哪里睡，就在哪里醒&#125;\n\n实现中断和虚假唤醒是可能的，需要将 this.wait() 其while方法用在循环中\nb. Lock 实现线程通信使用lock进行线程间通信,需要配合Condition接口使用。\nCondition的作用是对锁进行更精确的控制。\nCondition中的await()方法相当于Object的wait()方法，Condition中的signal()方法相当于Object的notify()方法，Condition中的signalAll()相当于Object的notifyAll()方法。\ncondition可以通俗的理解为条件队列。当一个线程在调用了await方法以后，直到线程等待的某个条件为真的时候才会被唤醒。这种方式为线程提供了更加简单的等待&#x2F;通知模式。Condition必须要配合锁一起使用，因为对共享状态变量的访问发生在多线程环境下。一个Condition的实例必须与一个Lock绑定，因此Condition一般都是作为Lock的内部实现。\n不同的是，Object中的wait(),notify(),notifyAll()方法是和”同步锁”(synchronized关键字)捆绑使用的；而Condition是需要与”互斥锁”&#x2F;“共享锁”捆绑使用的。\n12345678910111213141516public interface Condition &#123;\t// 造成当前线程在接到信号或被中断之前一直处于等待状态。\tvoid await()    // 造成当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。    boolean await(long time, TimeUnit unit)    // 造成当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。    long awaitNanos(long nanosTimeout)    // 造成当前线程在接到信号之前一直处于等待状态。    void awaitUninterruptibly()    // 造成当前线程在接到信号、被中断或到达指定最后期限之前一直处于等待状态。    boolean awaitUntil(Date deadline)    // 唤醒一个等待线程。    void signal()    // 唤醒所有等待线程。    void signalAll()&#125;\n\n\n\n1. Lock 实现简单互斥操作。lock实现一个由四个线程操作同一个变量,进行01切换的类\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class LockCommunication &#123;    public static void main(String[] args) &#123;        Share share = new Share();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 10; i++) &#123;                try &#123;                    share.add();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;,&quot;AA&quot;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 10; i++) &#123;                try &#123;                    share.minus();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;,&quot;BB&quot;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 10; i++) &#123;                try &#123;                    share.add();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;,&quot;CC&quot;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 10; i++) &#123;                try &#123;                    share.minus();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;,&quot;DD&quot;).start();    &#125;    /*lock实现一个由四个线程操作同一个变量,进行01切换的类*/    static class Share &#123;        private int number = 0;        // 新建锁对象        private ReentrantLock lock = new ReentrantLock();        //          private Condition condition = lock.newCondition();        // +1        public void add() throws InterruptedException &#123;            lock.lock();            try &#123;                while (number != 0) &#123;                    condition.await();                &#125;                number++;                System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number);                // 通知全部                condition.signalAll();            &#125; finally &#123;                lock.unlock();            &#125;        &#125;        //-1        public void minus() throws InterruptedException &#123;            lock.lock();            try &#123;                while (number != 1) &#123;                    condition.await();                &#125;                number--;                System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number);                condition.signalAll();            &#125; finally &#123;                lock.unlock();            &#125;        &#125;    &#125;&#125;\n\n\n\n2. Lock实现线程间通信定制化（自定义执行顺序）实现一个三个线程按顺序轮换执行即A-&gt;B-&gt;C-&gt;A-&gt;B-&gt;C….\n实现思路就是用一个信号flag来控制。\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/* lock 实现一个三个线程按顺序轮换执行即A-&gt;B-&gt;C-&gt;A-&gt;B-&gt;C....*/static class Custom &#123;    // 1--&gt;A 2--&gt;B 3--&gt;C    private int flag = 1;    private ReentrantLock lock = new ReentrantLock();    // 创建三个 condition    private Condition c1 = lock.newCondition();    private Condition c2 = lock.newCondition();    private Condition c3 = lock.newCondition();    // 打印3轮 参数为第几轮    public void print3(int loop) &#123;        // 上锁        lock.lock();        try &#123;            while (flag != 1) c1.await();            for (int i = 0; i &lt; 3; i++) &#123;                System.out.println(Thread.currentThread().getName() + &quot; :: &quot; + i + &quot; 轮数 :&quot; + loop);            &#125;            // 修改标志位            flag = 2;            // 通知c2            c2.signal();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            // 释放锁            lock.unlock();        &#125;    &#125;    public void print6(int loop) &#123;        // 上锁        lock.lock();        try &#123;            while (flag != 2) c2.await();            for (int i = 0; i &lt; 6; i++) &#123;                System.out.println(Thread.currentThread().getName() + &quot; :: &quot; + i + &quot; 轮数 :&quot; + loop);            &#125;            // 修改标志位            flag = 3;            // 通知c3            c3.signal();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            // 释放锁            lock.unlock();        &#125;    &#125;    public void print9(int loop) &#123;        // 上锁        lock.lock();        try &#123;            while (flag != 3) c3.await();            for (int i = 0; i &lt; 9; i++) &#123;                System.out.println(Thread.currentThread().getName() + &quot; :: &quot; + i + &quot; 轮数 :&quot; + loop);            &#125;            // 修改标志位            flag = 1;            // 通知c1            c1.signal();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            // 释放锁            lock.unlock();        &#125;    &#125;&#125;\n\n\n\n6. 集合线程安全a. ArrayList线程不安全问题打开ArrayList的源码,以add方法为例,显然他并没有使用synchronized或者lock进行并发控制,\n1234567891011/** * This helper method split out from add(E) to keep method * bytecode size under 35 (the -XX:MaxInlineSize default value), * which helps when add(E) is called in a C1-compiled loop. */private void add(E e, Object[] elementData, int s) &#123;    if (s ` elementData.length)        elementData = grow();    elementData[s] = e;    size = s + 1;&#125;\n\n编写一个多线程同时进行插入操作的程序,很容易会出现以下错误ConcurrentModificationException并发修改异常。\n123456789public static void main(String[] args) &#123;    ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();    for (int i = 0; i &lt; 20; i++) &#123;        new Thread(() -&gt; &#123;            list.add(UUID.randomUUID().toString().substring(0,8));            System.out.println(list);        &#125;, String.valueOf(i)).start();    &#125;&#125;\n\n\n\n常用的解决方案：\n\n\n\n使用Vector,是线程安全的，但是由于使用了synchronized同步锁，导致同一时间内只有一个线程能访问，效率较低。比较古老，JDK1.0 时期的解决方案。\n1List&lt;String&gt; list = new Vector&lt;&gt;();\n\n使用**Collections.synchronizedList()**来解决,也比较古老\n1List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;());\n\n使用CopyOnWrite;使用CopyOnWrite（写时复制）技术解决了这个问题，这一般需要很大的内存开销。\n1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;();\n\n1234567891011121314151617181920/*** Appends the specified element to the end of this list.** @param e element to be appended to this list* @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;)*/public boolean add(E e) &#123;    final ReentrantLock lock = this.lock;    lock.lock();    try &#123;        Object[] elements = getArray();        int len = elements.length;        Object[] newElements = Arrays.copyOf(elements, len + 1);        newElements[len] = e;        setArray(newElements);        return true;    &#125; finally &#123;        lock.unlock();    &#125;&#125;\n\nb. HashSet&#x2F;HashMap线程不安全问题1234567Set&lt;String&gt; set = new HashSet&lt;&gt;();for (int i = 0; i &lt; 20; i++) &#123;    new Thread(() -&gt; &#123;        set.add(UUID.randomUUID().toString().substring(0, 8));        System.out.println(set);    &#125;, String.valueOf(i)).start();&#125;\n\n在执行后,同样也会出现 java.util.ConcurrentModificationException异常\n12345678Exception in thread &quot;19&quot; java.util.ConcurrentModificationException\tat java.base/java.util.HashMap$HashIterator.nextNode(HashMap.java:1495)\tat java.base/java.util.HashMap$KeyIterator.next(HashMap.java:1518)\tat java.base/java.util.AbstractCollection.toString(AbstractCollection.java:456)\tat java.base/java.lang.String.valueOf(String.java:3352)\tat java.base/java.io.PrintStream.println(PrintStream.java:977)\tat collect.lambda$main$0(collect.java:21)\tat java.base/java.lang.Thread.run(Thread.java:830)\n\n同样也可以使用 Collections.synchronizedSet() CopyOnWriteArraySet 解决并发问题。\n12Set&lt;String&gt; set = Collections.synchronizedSet(new HashSet&lt;&gt;());Set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;();\n\n\n\nHashMap\nHashSet底层通过HashMap实现,HashSet通过给HashMap中的&lt;K,V&gt;的V给一个默认值PERSENT来生成HashSet。\nArrayList扩容默认一半，HashMap扩容默认一倍。\n可以使用ConcurrentHashMap Collections.synchronizedMap() 来解决并发问题。\nConcurrentHashMap在多线程编程中，将会是非常常用的类。\n12Map&lt;String,String&gt; map = new ConcurrentHashMap&lt;&gt;();Map&lt;String,String&gt; map = Collections.synchronizedMap(new HashMap&lt;String, String&gt;());\n\n\n\n7. 多线程锁这里重点关注的是线程执行顺序问题,锁是如何影响线程的执行顺序的。\na. 8种加锁情况synchronized实现同步的基础：java中的每一个对象都可以作为锁。this和class也是一种对象。\n具体表现为一下3中形式。\n\n 对于普通同步方法，锁是当前实例对象，锁的是当前对象this，\n\n\n 对于同步方法块，锁的是synchronized括号里配置的对象。\n\n\n 对于静态同步方法，锁是当前类的class对象\n\n\n\n下面的程序,默认先创建线程sendA,再创建线程sendB\n1234567891011public class LockProblem &#123;    static class Phone &#123;        public synchronized void sendA() throws Exception &#123;            //TimeUnit.SECONDS.sleep(2);            System.out.println(&quot;---sendA---&quot;);        &#125;        public synchronized void sendB() throws Exception &#123;            System.out.println(&quot;---sendB---&quot;);        &#125;    &#125;&#125;\n\n\n标准访问时,执行顺序如何? 不一定,取决于操作系统,但一般先start的先执行\nsynchronized加给普通方法,是锁的类对象,即This指针。\n对象锁\n\n 一个对象里面如果有多个synchronized方法，某一个时刻内，只要一个线程去调用其中的一个synchronized方法了，其他的线程都只能等待，换句话说，**某一个时刻内，只能有唯一一个线程去访问这些synchronized方法。**\n\n\n 锁的是当前对象this，被锁定后，其他的线程都不能进入到当前对象的其他的synchronized方法\n\n\n\n123456789101112131415Phone phone = new Phone();new Thread(() -&gt; &#123;    try &#123;        phone.sendA();    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;, &quot;A&quot;).start();new Thread(() -&gt; &#123;    try &#123;        phone.sendB();    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;, &quot;B&quot;).start();\n\nA方法内先设置暂停2秒方法,执行顺序如何? 先打印A,B等待A执行结束后打印B\n1234public synchronized void sendA() throws Exception &#123;    TimeUnit.SECONDS.sleep(2);    System.out.println(&quot;---sendA---&quot;);&#125;\n\n这是由于sendA方法加了synchronized,而sendA先抢到了这把对象锁，所以会在A打印结束后再打印B，即B要等待A完成才会执行。\n\n新增一个普通方法(不加synchronized),执行顺序如何?先执行普通方法\n普通方法为加锁,并非共享资源,不存在争抢。\n123public void sayHello()&#123;    System.out.println(&quot;---Hello---&quot;);&#125;\n\n123456789101112131415new Thread(() -&gt; &#123;    try &#123;        phone.sendA();    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;, &quot;A&quot;).start();new Thread(() -&gt; &#123;    try &#123;        phone.sayHello();    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;, &quot;B&quot;).start();\n\n两个资源类,分别执行时,哪个先执行?先打印B,A sleep结束后打印A\n两个资源类生成的是两个锁，互相无关\n12345Phone phone = new Phone();Phone phone2 = new Phone();phone.sendA();phone2.sendB();\n\n两个静态同步方法,一个资源类,哪个先执行? 先打印A,B等待A完成后执行\n锁的是类,即.class文件,和第六种锁相似,生成再多的类对象,公用的是一个锁\n12345678public static synchronized void sendA() throws Exception &#123;    TimeUnit.SECONDS.sleep(2);    System.out.println(&quot;---sendA---&quot;);&#125;public static synchronized void sendB() throws Exception &#123;    System.out.println(&quot;---sendB---&quot;);&#125;\n\n两个静态同步方法,两个资源类,哪个先执行? 先打印A,B等待A完成后执行\n锁的是类,即.class文件,和第六种锁相似,生成再多的类对象,公用的是一个锁\n12345678910111213public static synchronized void sendA() throws Exception &#123;    TimeUnit.SECONDS.sleep(2);    System.out.println(&quot;---sendA---&quot;);&#125;public static synchronized void sendB() throws Exception &#123;    System.out.println(&quot;---sendB---&quot;);&#125;Phone phone = new Phone();Phone phone2 = new Phone();phone.sendA();phone2.sendB();\n\n\n\n1个静态同步方法,1个普通同步方法,1个资源类,哪个先执行? 先打印B,A sleep结束后打印A\n对象和类都有锁，两把锁互相不冲突，所以B先打印，等A sleep结束后打印A。\n123456789public static synchronized void sendA() throws Exception &#123;    TimeUnit.SECONDS.sleep(2);    System.out.println(&quot;---sendA---&quot;);&#125;public synchronized void sendB() throws Exception &#123;    System.out.println(&quot;---sendB---&quot;);&#125;phone.sendA();phone.sendB();\n\n1个静态同步方法,1个普通同步方法,2个资源类,哪个先执行? 先打印B,A sleep结束后打印A。\n对象和类都有锁，两把锁互相不冲突，所以B先打印，等A sleep结束后打印A。\n1234Phone phone = new Phone();Phone phone2 = new Phone();phone.sendA();phone2.sendB();\n\nb. 公平锁和非公平锁\n公平锁：效率相对低\n非公平锁：效率高，但是线程容易饿死\n\nReentrantLock(true)为公平锁ReentrantLock(false)为非公平锁\n123456public ReentrantLock() &#123;    sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123;    sync = fair ? new FairSync() : new NonfairSync();&#125;\n\n公平锁的源码,很简单，它创建了一个访问的循环队列,队列中有线程就排队等候。\n123456789101112131415161718192021222324252627282930/*** Sync object for fair locks*/static final class FairSync extends Sync &#123;    private static final long serialVersionUID = -3000897897090466540L;    /**         * Fair version of tryAcquire.  Don&#x27;t grant access unless         * recursive call or no waiters or is first.         */    @ReservedStackAccess    protected final boolean tryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();        int c = getState();        if (c ` 0) &#123;            if (!hasQueuedPredecessors() &amp;&amp;                compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        else if (current ` getExclusiveOwnerThread()) &#123;            int nextc = c + acquires;            if (nextc &lt; 0)                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        return false;    &#125;&#125;\n\n\n\n非公平锁的情况\n1private final ReentrantLock lock = new ReentrantLock(false);\n\n之前实现的买表实例,非公平锁的情况下,seller2和seller3都不能买到票，票全都被线程1买走了。\n12345678910111213seller1买了1张票,剩余29张票seller1买了1张票,剩余28张票seller1买了1张票,剩余27张票seller1买了1张票,剩余26张票seller1买了1张票,剩余25张票seller1买了1张票,剩余24张票seller1买了1张票,剩余23张票seller1买了1张票,剩余22张票seller1买了1张票,剩余21张票...seller2没买到...seller3没买到\n\n\n\n公平锁的情况\n1private final ReentrantLock lock = new ReentrantLock(true);\n\n12345678910seller1买了1张票,剩余29张票seller2买了1张票,剩余28张票seller3买了1张票,剩余27张票seller1买了1张票,剩余26张票seller2买了1张票,剩余25张票seller3买了1张票,剩余24张票seller1买了1张票,剩余23张票seller2买了1张票,剩余22张票seller3买了1张票,剩余21张票...\n\nc. 可重入锁可重入锁，指的是以线程为单位，当一个线程获取对象锁之后，这个线程可以再次获取本对象上的锁，而其他的线程是不可以的。\n可重入锁的意义之一在于防止死锁。\n实现原理是通过为每个锁关联一个请求计数器和一个占有它的线程。当计数为0时，认为锁是未被占有的；线程请求一个未被占有的锁时，JVM将记录锁的占有者，并且将请求计数器置为1 。\n如果同一个线程再次请求这个锁，计数器将递增；\n每次占用线程退出同步块，计数器值将递减。直到计数器为0,锁被释放。\nSynchronized(隐式) 和 Lock(显式) 都是可重入锁。\n可重入的实例\n由此可见,加锁过程中可以重复进入这个锁对象,而不会说\n12345678910111213//synchronizedObject o = new Object();new Thread(() -&gt; &#123;    synchronized (o) &#123;        System.out.println(Thread.currentThread().getName()+&quot;外层&quot;);        synchronized (o)&#123;            System.out.println(Thread.currentThread().getName()+&quot;中层&quot;);            synchronized (o)&#123;                System.out.println(Thread.currentThread().getName()+&quot;内层&quot;);            &#125;        &#125;    &#125;&#125;, &quot;t1&quot;).start();\n\n123456789101112131415161718//lockReentrantLock lock = new ReentrantLock();new Thread(() -&gt; &#123;    try &#123;        lock.lock();        System.out.println(Thread.currentThread().getName() + &quot;外层&quot;);        try &#123;            lock.lock();            System.out.println(Thread.currentThread().getName() + &quot;内层&quot;);        &#125; finally &#123;            // 内部是自己的锁不释放锁也可以正常执行,这也是可重入锁的特点            // 但是内部是其他的锁不释放则不行 \t\t   // lock.unlock();        &#125;    &#125; finally &#123;        lock.unlock();    &#125;&#125;, &quot;t2&quot;).start();\n\n\n\n8. 死锁两个或以上的进程因为争夺资源而造成互相等待资源的现象称为死锁。如果没有外力的作用，他们一般不能再执行下去\n\n\n\n\n产生死锁的必要条件：\n\n互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。\n请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。\n不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。\n环路等待条件：在发生死锁时，必然存在一个进程–资源的环形链。\n\n查看进程堆栈信息的指令\n\nwindows  jps\nLinux   ps -ef\n\n9. Callable 接口对比Callable接口和Runnable接口\n\nCallable实现的方法是call(),Runnable实现的方法是run().\nCallable的任务执行后有返回值，而Runnable的任务没有返回值\ncall方法可以抛出异常，run方法不可以\n\n1234567891011121314151617181920212223public class InheritedInterface &#123;    public static class MyThread implements Runnable &#123;        @Override        public void run() &#123;            System.out.println(&quot;--- in Runnable ---&quot;);        &#125;    &#125;    private static class MyThreadCall implements Callable&lt;String&gt; &#123;        @Override        public String call() throws Exception &#123;            System.out.println(&quot;--- in Callable ---&quot;);            return &quot;Callable Return&quot;;        &#125;    &#125;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        Thread t1 = new Thread(new MyThread());        FutureTask futureTask = new FutureTask(new MyThreadCall());        Thread t2 = new Thread(futureTask);        t1.start();        t2.start();        System.out.println(futureTask.get());    &#125;&#125;\n\n通过Thread创建线程\n\nRunnable Thread t1 &#x3D; new Thread(new MyThread());\n\nCallable Thread t2 &#x3D; new Thread(new FutureTask(new MyThreadCall()));\n不可以通过**new Thread(new MyThread2());**创建线程,因为Thread的构造函数中没有Callable接口的参数设置直接替换不可以，只能用下面这种线程创建方法（找一个类，即和Runnable接口有关系，又和Callable接口有关系）\n\n\n\n\n发现Runnable接口有实现类FutureTask（中间对象）,FutureTask的构造函数有Callable参数，通过FutureTask创建线程对象\n也可以使用lamda表达式来简写\n12345//lam表达式FutureTask&lt;Integer&gt; futureTask2 = new FutureTask&lt;&gt;(()-&gt;&#123;    System.out.println(Thread.currentThread().getName()+&quot; come in callable&quot;);    return 1024;&#125;);\n\n\n\n如果两个线程都调用了同一个FutureTask,那么FutureTask中的call方法只会执行一次\n123FutureTask futureTask = new FutureTask(new MyThreadCall());new Thread(futureTask,&quot;A&quot;),start();new Thread(futureTask,&quot;B&quot;),start();\n\n\n\nCallable返回值\nCallable接口返回值通过 futureTask.get()来调用,只要调用futureTask.get(),主线程就要阻塞等待线程执行完毕,因此:一般放在最后调用线程的返回值,为了尽量让线程计算完再获取返回值\n\n**get()**获取结果\n**isDone()**判断是否计算结束\n\n10. 辅助类a. 减少计数 CountDownLatchCountDownLatch 类可以设置一个计数器，然后通过 countDown 方法来进行减 1 的操作，使用 await 方法等待计数器不大于 0，然后继续执行 await 方法之后的语句。\n如果不加 CountDownLatch类，会出现线程混乱执行，同学还未离开教室班长就已经锁门了\n123456789101112131415161718192021public static void main(String[] args) throws InterruptedException &#123;    /*实现5个同学陆续离开教室,全部离开后锁门*/    /*设置计数器*/    CountDownLatch countDownLatch = new CountDownLatch(5);    for (int i = 0; i &lt; 5; i++) &#123;        new Thread(() -&gt; &#123;            System.out.println(Thread.currentThread().getName()+&quot;离开&quot;);            // 计数器 -1            countDownLatch.countDown();        &#125;, &quot;No.&quot; + i).start();    &#125;    //等待    countDownLatch.await();    System.out.println(Thread.currentThread().getName()+&quot;锁门&quot;);&#125; No.0离开No.2离开No.3离开No.1离开No.4离开main锁门\n\n\n\nb. 循环栅栏 CyclicBarrier该类是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点，会执行定义的代码。\n在设计一组固定大小的线程的程序中，这些线程必须互相等待，这个类很有用，因为barrier在释放等待线程后可以重用，所以称为循环barrier\n下面这个例子中:\n\n每7个线程执行后,定义的 **new CyclicBarrier(NUMBER, () -&gt; {System.out.println(“—集齐7颗龙珠召唤神龙—“);});**中的代码才会执行。\n只有前面7个线程都执行完毕，后面的一轮线程才会开始执行\n**cyclicBarrier.await();**之后的代码必须等达到CyclicBarrier的屏障才会执行\n**await()**在所有的参与者都已经在此barrier上调用await方法之前，一直等待。\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* 集齐7颗龙珠召唤神龙 */final int NUMBER = 7;CyclicBarrier cyclicBarrier = new CyclicBarrier(NUMBER, () -&gt; &#123;    System.out.println(&quot;---集齐7颗龙珠召唤神龙---&quot;);&#125;);// 集齐龙珠的过程for (int i = 0; i &lt; 15; i++) &#123;    new Thread(() -&gt; &#123;        try &#123;            System.out.println(Thread.currentThread().getName() + &quot;星龙珠已收集.&quot;);            // 等待            cyclicBarrier.await();            // cyclicBarrier.await();之后的代码必须等达到CyclicBarrier的屏障才会执行            System.out.println(&quot;WDNMD&quot;);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; catch (BrokenBarrierException e) &#123;            e.printStackTrace();        &#125;    &#125;, String.valueOf(i + 1)).start();&#125;1星龙珠已收集.3星龙珠已收集.2星龙珠已收集.4星龙珠已收集.5星龙珠已收集.6星龙珠已收集.7星龙珠已收集.8星龙珠已收集.---集齐7颗龙珠召唤神龙---9星龙珠已收集.WDNMD10星龙珠已收集.11星龙珠已收集.12星龙珠已收集.WDNMDWDNMDWDNMD13星龙珠已收集.WDNMDWDNMDWDNMD15星龙珠已收集.14星龙珠已收集.---集齐7颗龙珠召唤神龙---WDNMDWDNMD...\n\n\n\nc. 信号灯 Semaphore一个计数信号量，从概念上将，信号量维护了一个许可集，如有必要，在许可可用前会阻塞每一个acquire()，然后在获取该许可。每个release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动\n具体常用的构造方法有：Semaphore(int permits)创建具有给定的许可数和非公平的公平设置的Semapore\n具体常用的方法有：acquire()从此信号量获取一个许可，在提供一个许可前一直将线程阻塞，否则线程被中断release()释放一个许可，将其返回给信号量\n设置许可数量Semaphore semaphore &#x3D; new Semaphore(3);一般acquire(）都会抛出异常，release在finally中执行\n123456789101112131415161718192021222324252627282930313233/*Semaphore实现6辆汽车停到3个停车位*/// 构造函数传参为许可数量Semaphore semaphore = new Semaphore(3);for (int i = 0; i &lt; 6; i++) &#123;    new Thread(() -&gt; &#123;        try &#123;            // 获取许可            semaphore.acquire();            System.out.println(Thread.currentThread().getName() + &quot;抢到了车位&quot;);            // 随机停车时间            TimeUnit.SECONDS.sleep(new Random().nextInt(5));            System.out.println(Thread.currentThread().getName() + &quot;离开了车位&quot;);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            // 释放            semaphore.release();        &#125;    &#125;, i + &quot;号车&quot;).start();&#125;1号车抢到了车位0号车抢到了车位2号车抢到了车位0号车--离开了车位2号车--离开了车位3号车抢到了车位4号车抢到了车位1号车--离开了车位5号车抢到了车位5号车--离开了车位4号车--离开了车位3号车--离开了车位\n\n\n\n11. 读写锁悲观锁：单独每个人完成事情的时候，执行上锁解锁。解决并发中的问题，不支持并发操作，只能一个一个操作，效率低乐观锁：每执行一件事情，都会比较数据版本号，谁先提交，谁先提交版本号\n表锁：整个表操作，不会发生死锁行锁：每个表中的单独一行进行加锁，会发生死锁\n读锁：共享锁（可以有多个人读），会发生死锁写锁：独占锁（只能有一个人写），会发生死锁\n读写锁：一个资源可以被多个读线程访问，也可以被一个写线程访问，但不能同时存在读写线程，读写互斥，读共享\n编程方式\n12345678910// 创建读写锁对象private ReadWriteLock rwLock = new ReentrantReadWriteLock();//添加写锁rwLock.writeLock().lock();// 释放锁rwLock.writeLock().unlock();// 添加读锁rwLock.readLock().lock();// 释放读锁rwLock.readLock().unlock();\n\n\n\n模拟一个读写Map的实例\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class WriteReadLock &#123;    public static void main(String[] args) &#123;        MyCache myCache = new MyCache();        //  创建线程放数据        for (int i = 0; i &lt; 3; i++) &#123;            final int num = i;            new Thread(() -&gt; &#123;                myCache.put(num + &quot;&quot;, num + &quot;&quot;);            &#125;, String.valueOf(i)).start();        &#125;        //  创建线程取数据        for (int i = 0; i &lt; 3; i++) &#123;            final int num = i;            new Thread(() -&gt; &#123;                myCache.get(num + &quot;&quot;);            &#125;, String.valueOf(i)).start();        &#125;    &#125;    static class MyCache &#123;        // 创建Map集合        private Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();        private ReadWriteLock rwLock = new ReentrantReadWriteLock();        // 放数据        public void put(String key, Object val) &#123;            //添加写锁            rwLock.writeLock().lock();            try &#123;                System.out.println(Thread.currentThread().getName() + &quot; 正在进行写操作 &quot; + key);                TimeUnit.MICROSECONDS.sleep(300);                map.put(key, val);                System.out.println(Thread.currentThread().getName() + &quot; 写完了 &quot; + key);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; finally &#123;                // 释放锁                rwLock.writeLock().unlock();            &#125;        &#125;        // 取数据        public Object get(String key) &#123;            // 添加读锁            rwLock.readLock().lock();            Object res = null;            try &#123;                System.out.println(Thread.currentThread().getName() + &quot; 正在进行读操作 &quot; + key);                TimeUnit.MICROSECONDS.sleep(300);                res = map.get(key);                System.out.println(Thread.currentThread().getName() + &quot; 读完了 &quot; + key);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; finally &#123;                // 释放读锁                rwLock.readLock().unlock();            &#125;            return res;        &#125;    &#125;&#125;\n\n不加读写锁之前,出现读写不互斥,未写完就读等问题\n1234567891011122 正在进行读操作 21 正在进行读操作 12 正在进行写操作 20 正在进行读操作 00 正在进行写操作 01 正在进行写操作 12 读完了 2\t\t\t// 还未写完就读了1 读完了 10 写完了 02 写完了 20 读完了 01 写完了 1\n\n加了锁之后\n1234567891011121 正在进行读操作 1   // 读操作并发0 正在进行读操作 0\t  // 读操作并发2 正在进行读操作 2   // 读操作并发2 读完了 21 读完了 10 读完了 01 正在进行写操作 1   // 写操作独占1 写完了 12 正在进行写操作 2   // 写操作独占2 写完了 20 正在进行写操作 0   // 写操作独占0 写完了 0\n\n\n\n* 锁降级将写锁降为读锁。降级后读锁不能升级为写锁。\nJDK8中对锁降级的说明:获取写锁后,在写锁释放之前,可以获得读锁。而读锁过程中不能获得写锁。\n1234567891011121314151617181920212223242526272829303132333435ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();ReentrantReadWriteLock.ReadLock readLock = rwLock.readLock();ReentrantReadWriteLock.WriteLock writeLock = rwLock.writeLock();// 锁降级// 获取写锁writeLock.lock();System.out.println(&quot;---Write---&quot;);// 获取读锁readLock.lock();System.out.println(&quot;---Read---&quot;);writeLock.unlock();readLock.unlock();//------结果----------// ---Write---  // ---Read---// 如果读锁中获得写锁// 获取读锁readLock.lock();System.out.println(&quot;---Read---&quot;);// 获取写锁writeLock.lock();System.out.println(&quot;---Write---&quot;);readLock.unlock();writeLock.unlock();// ----结果-------Read---写不能执行\n\n\n\n12. 阻塞队列\n\n阻塞队列是共享队列（多线程操作），一端输入，一端输出,不能无限放队列，满了之后就会进入阻塞，取出也同理\n\n当队列是空的，从队列中获取元素的操作将会被阻塞\n当队列是满的，从队列中添加元素的操作将会被阻塞\n试图从空的队列中获取元素的线程将会被阻塞，直到其他线程往空的队列插入新的元素\n试图向已满的队列中添加新元素的线程将会被阻塞，直到其他线程从队列中移除一个或多个元素或者完全清空，使队列变得空闲起来并后续新增\n\n使用阻塞队列BlockingQueue好处在于不用关心真实的线程的阻塞与唤醒过程,不用关心实现细节.\n\n\na. 阻塞队列的分类\nArrayBlockingQueue  基于数组的阻塞队列,由数组结构组成的有界阻塞队列\nArrayBlockingQueue 在生产者放入数据和消费者获取数据，都是共用同一个锁对象，无法并行\n\nLinkedBlockingQueue  基于链表的阻塞队列由链表结构组成的有界（但大小默认值为integer.MAX_VALUE）阻塞队列\n\n\n  之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能\n\nDelayQueue 使用优先级队列实现的延迟无界阻塞队列\nDelayQueue 中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞\n\nPriorityBlockingQueue 基于优先级的阻塞队列支持优先级排序的无界阻塞队列,不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者\n\nSynchronousQueue 一种无缓冲的等待队列相对于有缓冲的 BlockingQueue 来说，少了一个中间经销商的环节（缓冲区）不存储元素的阻塞队列，也即单个元素的队列\n声明一个 SynchronousQueue 有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别:• 公平模式：SynchronousQueue 会采用公平锁，并配合一个 FIFO 队列来阻塞多余的生产者和消费者，从而体系整体的公平策略；• 非公平模式（SynchronousQueue 默认）：SynchronousQueue 采用非公平锁，同时配合一个 LIFO 队列来管理多余的生产者和消费者\n而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理\n\nLinkedTransferQueue 由链表结构组成的无界阻塞 TransferQueue 队列由链表组成的无界阻塞队列\n预占模式。意思就是消费者线程取元素时，如果队列不为空，则直接取走数据，若队列为空，生成一个节点（节点元素为 null）入队，消费者线程被等待在这个节点上，生产者线程入队时发现有一个元素为 null 的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒的消费者线程取走元素，从调用的方法返回\n\nLinkedBlockingDeque由链表结构组成的双向阻塞队列\n阻塞有两种情况\n插入元素时: 如果当前队列已满将会进入阻塞状态，一直等到队列有空的位置时再该元素插入，该操作可以通过设置超时参数，超时后返回 false 表示操作失败，也可以不设置超时参数一直阻塞，中断后抛出 InterruptedException异常读取元素时: 如果当前队列为空会阻塞住直到队列不为空然后返回元素，同样可以通过设置超时参数\n\n\nb. 阻塞队列使用12345678910111213BlockingQueue queue = new ArrayBlockingQueue&lt;String&gt;(3);// 第一组queue.add(&quot;a&quot;);  // 向队列中加元素queue.offer(&quot;c&quot;, 100, TimeUnit.SECONDS); // 设置超时失效queue.element(); // 返回队列头元素queue.remove();  // 移除队列头// 第二组queue.offer(&quot;a&quot;); queue.poll();queue.peek();// 第三组queue.put(&quot;a&quot;);  // 超过容量阻塞queue.take();       // 空了会阻塞\n\n\n\n13. 线程池 ThreadPool线程池：一种线程使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代价。\n线程池不仅能够保证内核的充分利用，还能防止过分调度。\n线程池特点：\n\n降低资源消耗: 通过重复利用已创建的线程降低线程创建和销毁造成的销耗。\n提高响应速度: 当任务到达时，任务可以不需要等待线程创建就能立即执行。\n提高线程的可管理性: 线程是稀缺资源，如果无限制的创建，不仅会销耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n线程池框架：\nJava 中的线程池是通过 Executor 框架实现的，该框架中用到了 Executor，Executors，ExecutorService，ThreadPoolExecutor 这几个类。\n\n\n线程池根据容量特点可以分为三类：\n这三类都使用的是 ThreadPoolExecutor 来创建的线程池。\n\n一池N线程\n12// 一池多线程ExecutorService threadPool1 = Executors.newFixedThreadPool(3);\n\n一池一线程\n12// 一池一线程ExecutorService threadPool2 = Executors.newSingleThreadExecutor();\n\n线程池可扩容\n12// 线程池可扩容ExecutorService threadPool3 = Executors.newCachedThreadPool();\n\n线程池使用实例\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static void main(String[] args) &#123;    // 一池多线程    ExecutorService threadPool1 = Executors.newFixedThreadPool(3);    try &#123;        /*模拟5个线程放入大小为3的线程池*/        for (int i = 0; i &lt; 10; i++) &#123;            threadPool1.execute(() -&gt; &#123;                System.out.println(Thread.currentThread().getName() + &quot; 办理业务&quot;);            &#125;);        &#125;    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125; finally &#123;        // 关闭线程池        threadPool1.shutdown();    &#125;    // 一池一线程    ExecutorService threadPool2 = Executors.newSingleThreadExecutor();    try &#123;        /*模拟5个线程放入大小为1的线程池*/        for (int i = 0; i &lt; 5; i++) &#123;            threadPool2.execute(() -&gt; &#123;                System.out.println(Thread.currentThread().getName() + &quot; 办理业务&quot;);            &#125;);        &#125;    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125; finally &#123;        // 关闭线程池        threadPool2.shutdown();    &#125;    // 线程池可扩容    ExecutorService threadPool3 = Executors.newCachedThreadPool();    try &#123;        /*模拟5个线程放入大小为1的线程池*/        for (int i = 0; i &lt; 155; i++) &#123;            threadPool3.execute(() -&gt; &#123;                System.out.println(Thread.currentThread().getName() + &quot; 办理业务&quot;);            &#125;);        &#125;    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125; finally &#123;        // 关闭线程池        threadPool3.shutdown();    &#125;&#125;\n\n\n\na. ThreadPoolExecutor 参数含义一池N线程、一池一线程、线程池可扩容, 这三个底层都是通过ThreadPoolExecutor实现线程池创建的。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*** Creates a new &#123;@code ThreadPoolExecutor&#125; with the given initial* parameters.** @param corePoolSize the number of threads to keep in the pool, even*        if they are idle, unless &#123;@code allowCoreThreadTimeOut&#125; is set* @param maximumPoolSize the maximum number of threads to allow in the*        pool* @param keepAliveTime when the number of threads is greater than*        the core, this is the maximum time that excess idle threads*        will wait for new tasks before terminating.* @param unit the time unit for the &#123;@code keepAliveTime&#125; argument* @param workQueue the queue to use for holding tasks before they are*        executed.  This queue will hold only the &#123;@code Runnable&#125;*        tasks submitted by the &#123;@code execute&#125; method.* @param threadFactory the factory to use when the executor*        creates a new thread* @param handler the handler to use when execution is blocked*        because the thread bounds and queue capacities are reached* @throws IllegalArgumentException if one of the following holds:&lt;br&gt;*         &#123;@code corePoolSize &lt; 0&#125;&lt;br&gt;*         &#123;@code keepAliveTime &lt; 0&#125;&lt;br&gt;*         &#123;@code maximumPoolSize &lt;= 0&#125;&lt;br&gt;*         &#123;@code maximumPoolSize &lt; corePoolSize&#125;* @throws NullPointerException if &#123;@code workQueue&#125;*         or &#123;@code threadFactory&#125; or &#123;@code handler&#125; is null*/public ThreadPoolExecutor(int corePoolSize,\t\t\t\t\t// 常驻线程数量                          int maximumPoolSize,\t\t\t\t// 最大线程数量                          long keepAliveTime,\t\t\t\t// 线程存活时间                          TimeUnit unit,\t\t\t\t\t// 存活时间单位                          BlockingQueue&lt;Runnable&gt; workQueue,  // 阻塞队列                          ThreadFactory threadFactory,\t\t  // 线程工厂,用于创建线程                          RejectedExecutionHandler handler) &#123;  // 拒绝策略,当线程池爆满时的拒绝接收线程的策略    if (corePoolSize &lt; 0 ||        maximumPoolSize &lt;= 0 ||        maximumPoolSize &lt; corePoolSize ||        keepAliveTime &lt; 0)        throw new IllegalArgumentException();    if (workQueue ` null || threadFactory ` null || handler ` null)        throw new NullPointerException();    this.corePoolSize = corePoolSize;    this.maximumPoolSize = maximumPoolSize;    this.workQueue = workQueue;    this.keepAliveTime = unit.toNanos(keepAliveTime);    this.threadFactory = threadFactory;    this.handler = handler;&#125;\n\n\n\nRejectedExecutionHandler 线程池的饱和拒绝策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略:\n\nAbortPolicy: 直接抛出异常，默认策略；\nCallerRunsPolicy: 用调用者所在的线程来执行任务；\nDiscardOldestPolicy: 丢弃阻塞队列中靠最前的任务，并执行当前任务；\nDiscardPolicy: 直接丢弃任务；\n\nb. 线程池工作流程\n\n1.在创建了线程池后,等待提交过来的任务请求.\n2.当调用execute()方法添加一个请求任务时,线程池就会做如下判断:\n 2.1 如果正在运行的线程数量小于corePoolSize,那么马上创建线程运行这个任务\n 2.2 如果正在运行的线程数量大于或等于corePoolSize,那么将这个任务放入队列\n 2.3 如果这时候队列满了且正在运行的线程数量还小于maximumPoolSize,那么还是要创建非核心线程立刻运行这个任务\n 2.4 如果对队列满了且正在运行的线程数量大于或等于maximumPoolSize,那么线程池会启动饱和拒绝策略来执行.\n3.当一个线程完成任务时,它会从队列中取下一个任务来执行.\n4.当一个线程无事可做超过一定的时间(keepAliveTime)时,线程池会判断:\n 4.1 如果当前运行的线程数大于corePoolSize,那么这个线程就会被停掉\n 4.2 所以线程池的所有任务完成后它最终会收缩到corePoolSize的大小\nc. 自定义线程池实际在开发中不使用Executors创建，而是通过ThreadPoolExecutor的方式，规避资源耗尽风险\nExecutors线程池的弊端:\n\nFixedThreadPool和SingleThreadExecutor 允许的请求队列长度为Integer.MAX_VALUE(0x7fffffff);*可能会造成大量的请求堆积,导致*OOM.\nCachedThreadPool和 ScheduledThreadPoolExecutor 允许创建线程数量为 Integer.MAX_VALUE(0x7fffffff);,可能会创建大量线程,导致OOM.\n\n如何自定义线程池\n1234567891011121314151617181920212223ExecutorService threadPool = new ThreadPoolExecutor(    corePoolSize 2,    maximumPoolSize 5,    keepAliveTime 2L,    TimeUnit.SECONDS,    new ArrayBlockingQueue&lt;&gt;(3),    Executors.defaultThreadFactory(),    new ThreadPoolExecutor.AbortPolicy());// 自定义线程池使用try &#123;    /*模拟5个线程放入大小为5的线程池*/    for (int i = 0; i &lt; 5; i++) &#123;        threadPool.execute(() -&gt; &#123;            System.out.println(Thread.currentThread().getName() + &quot; 办理业务&quot;);        &#125;);    &#125;&#125; catch (Exception e) &#123;    e.printStackTrace();&#125; finally &#123;    // 关闭线程池    threadPool.shutdown();&#125;\n\n\n\n\n\n14. 拆分(Fork)合并(Join)框架Fork&#x2F;Join框架是Java并发工具包中的一种可以将一个大任务拆分为很多小任务来异步执行的工具，自JDK1.7引入。\n将一个大的任务拆分成多个子任务进行并行处理，最后将子任务结果合并成最后的计算结果，该算法相当于递归，二分。\n123456789101112131415161718192021222324252627public class ForkJoinDemo &#123;    static class fibonacci extends RecursiveTask&lt;Integer&gt; &#123;        final int n;        // 创建有参构造        fibonacci(int n) &#123; this.n = n; &#125;        @Override        protected Integer compute() &#123;            if (n &lt;= 1) return n;            fibonacci f1 = new fibonacci(n - 1);            f1.fork();            fibonacci f2 = new fibonacci(n - 2);            return f2.compute() + f1.join();        &#125;    &#125;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        // 创建任务对象        fibonacci f = new fibonacci(10);        // 创建分支合并池对象        ForkJoinPool forkJoinPool = new ForkJoinPool();        ForkJoinTask&lt;Integer&gt; forkJoinTask = forkJoinPool.submit(f);        // 获取合并之后的结果        Integer res = forkJoinTask.get();        System.out.println(res);        // 关闭池对象        forkJoinPool.shutdown();    &#125;&#125;\n\n\n\n15. CompletableFuture 异步回调CompletableFuture 在 Java 里面被用于异步编程，异步通常意味着非阻塞，可以使得我们的任务单独运行在与主线程分离的其他线程中，并且通过回调可以在主线程中得到异步任务的执行状态，是否完成，和是否异常等信息\n类中的具体引用类以及接口：\n\n\nCompletableFuture 实现了 Future, CompletionStage 接口，实现了 Future接口就可以兼容现在有线程池框架，而 CompletionStage 接口才是异步编程的接口抽象，里面定义多种异步方法，通过这两者集合，从而打造出了强大的CompletableFuture 类\n异步调用没有返回值方法runAsync异步调用有返回值方法supplyAsync\n主线程调用 get 方法会阻塞\n12345678910111213141516171819202122232425262728293031323334353637public class CompletableFutureDemo &#123;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        // 异步调用 无返回值        CompletableFuture&lt;Void&gt; completableFuture = CompletableFuture.runAsync(() -&gt; &#123;            System.out.println(Thread.currentThread().getName() + &quot;--异步调用 无返回值&quot;);        &#125;);        completableFuture.get();        // 异步调用 有返回值        CompletableFuture&lt;Integer&gt; completableFuture1 = CompletableFuture.supplyAsync(() -&gt; &#123;            System.out.println(Thread.currentThread().getName() + &quot;----异步调用 有返回值&quot;);            int i  =1 / 0;            return 1024;        &#125;);        completableFuture1.whenComplete((t, u) -&gt; &#123;            System.out.println(&quot;--t=&quot; + t);            System.out.println(&quot;--u=&quot; + u);        &#125;).get();    &#125;&#125;ForkJoinPool.commonPool-worker-19--异步调用 无返回值ForkJoinPool.commonPool-worker-19----异步调用 有返回值--t=null // 没异常为 1024 即返回值--u=java.util.concurrent.CompletionException: java.lang.ArithmeticException: / by zeroException in thread &quot;main&quot; java.util.concurrent.ExecutionException: java.lang.ArithmeticException: / by zero\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2070)\tat CompletableFutureDemo.main(CompletableFutureDemo.java:21)Caused by: java.lang.ArithmeticException: / by zero\tat CompletableFutureDemo.lambda$main$1(CompletableFutureDemo.java:15)\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1771)\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1763)\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1016)\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1665)\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1598)\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n\n\n\n\n\n","slug":"JUC","date":"2022-04-07T12:19:18.000Z","categories_index":"互联网八股","tags_index":"Java,JUC","author_index":"张 凡"},{"id":"7f77c660cadf02b64dd36120e903f5f0","title":"Mysql","content":"1. 概述MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。\n\n\n一条SQL语句的执行流程如下:\n\n建立连接。先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n\n如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。\n如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n\n\n查询缓存。连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\n​    MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之**前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。&#96;key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n​    查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表。\n需要注意的是，&#96;MySQL 8.0 版本直接将查询缓存的整块功能删掉了**，也就是说 8.0 开始彻底没有这个功能了。\n\n\n语法分析。如果没有命中查询缓存，就要开始真正执行语句了。\n首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n\n\n语法优化。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n所有的现代数据库都在用基于成本的优化（即CBO）来优化查询。道理是针对每个运算设置一个成本，通过应用成本最低廉的一系列运算，来找到最佳的降低查询成本的方法。对于联接操作，我会专注于它们的时间复杂度，但是，数据库优化器计算的是它们的 CPU 成本、磁盘 I&#x2F;O 成本、和内存需求。\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。\n\n\n&#96;SQl执行**。\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限。\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n1mysql&gt; select * from T where ID=10;\n\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n\n调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n至此，这个语句就执行完成了。\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n\n\n日志记录。日志记录是数据的一个重要组成部分，这是DBA进行恢复，查错，优化的主要依据。\n日志记录在更新操作上显得尤为重要，Mysql有两个主要日志：&#96;redo log（重做日志）和 binlog（归档日志）**\na. redo Log\n举个例子来介绍一下日志的记录方式，如果有人要赊账或者还账的话，掌柜一般有两种做法：\n\n一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；\n另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。\n\n在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。\n这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。\n​    而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 &#96;WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。**\n​    当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。\n​    InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。\n\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。\nb. BinLog\n​    上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n​    最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。\n这两种日志有以下三点不同。\n\nredo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\nredo log 是物理日志**，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志**，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。\nredo log 是循环写的，空间固定会用完**；binlog 是可以追加写入的**。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n以一条更新或插入记录为例,日志的写过程如下:\n\n引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n执行器调用引擎的提交事务接口，引擎把刚刚写入的 &#96;redo log 改成提交（commit）状态**，更新完成。\n\n将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是****”两阶段提交”****。\n为什么必须有“两阶段提交”呢？\n这是为了让两份日志之间的逻辑一致。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。如果当一个日志写完之后,而另外一个未写完,那么就会造成数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。\n\n\n2. 事务隔离事务的四个特性: ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）\n\n原子性: 事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。\n回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。\n\n一致性: 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。\n\n隔离性: 一个事务所做的修改在最终提交以前，对其它事务是不可见的。\n\n持久性: 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。\n可以通过数据库备份和恢复来实现，在系统发生崩溃时，使用备份的数据库进行数据恢复。\n\n\n\n主要讲事务的隔离性。\n​    隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。&#96;SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。**\n\n读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。\n读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。\n这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n为什么建议你尽量不要使用长事务。\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n实现事务隔离的原理InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。\nInnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。\n\n对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n\n而当前读，总是读取已经提交完成的最新版本。\n你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\n3. 索引索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。\na. 哈希表\n哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。\nb. 有序数组\n有序数组在等值查询和范围查询场景中的性能就都非常优秀。如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。\n有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。\nc. 搜索树\n二叉搜索树的查询复杂度是 $O(log_2(N))$ ，为了保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。 二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。\n为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。\n以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\na. InnoDB 的索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，&#96;InnoDB 使用了 B+ 树索引模型**，所以数据都是存储在 B+ 树中的。\n索引类型分为主键索引和非主键索引。\n主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？\n\n如果语句是 select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；\n如果语句是 select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。\n\n主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。\n1. 覆盖索引由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？\n也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n2. 最左前缀B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。关于最左前缀,看下面这个例子:\n\n\n\n当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。\n如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。\n\n\n3. 索引下推在不得不回表时,如果查询语句对联合索引上的其他字段有特别约束,可以先进行筛选再回表。\nb. 索引选择和实践普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。\n当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。\n在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。\n创建索引可以使用的方式有：\n\n直接创建完整索引，这样可能比较占用空间；\n创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。\n4. 锁根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。\n应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。\n但是加锁需要消耗资源，锁的各种操作(包括获取锁、释放锁、以及检查锁状态)都会增加系统开销。因此封锁粒度越小，系统开销就越大。\n在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。\na. 全局锁全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 &#96;Flush tables with read lock (FTWRL)**。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的写语句会被阻塞。\n全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。\n以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。\n但是让整库都只读，听上去就很危险：\n\n如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\nb. 表级锁MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。\n表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n另一类表级的锁是 MDL（metadata lock)。&#96;MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。**你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n\n读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\nc. 行锁MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。\n1. 两阶段锁加锁和解锁分为两个阶段进行。\n在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n两段锁协议可能会造成死锁。\n我们可以主动进行死锁检测，主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。死锁检测要耗费大量的 CPU 资源。\n减少死锁的方案：\n\n如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。\n\n控制并发度\n\n将一行改成逻辑上的多行来减少锁冲突。\n\n\n","slug":"Mysql","date":"2022-04-07T06:17:50.000Z","categories_index":"","tags_index":"数据库,Mysql","author_index":"张 凡"},{"id":"d1660779e842dc0a9949e0b888a18409","title":"Reids","content":"1. NoSQLNoSQL（ NoSQL &#x3D; Not Only SQL ），意即不仅仅是 SQL，泛指非关系型的数据库。\nNoSQL 不依赖业务逻辑方式存储，而以简单的 key-value 模式存储。因此大大的增加了数据库的扩展能力。\n\n不遵循 SQL 标准。\n不支持 ACID。\n远超于 SQL 的性能。\n\n适用于的场景\n\n对数据高并发的读写；\n海量数据的读写；\n对数据高可扩展性的。\n\n不适用的场景\n\n需要事务支持；\n基于 sql 的结构化查询存储，处理复杂的关系，需要即席查询。\n\n常见的 NoSQL 数据库\n\nRedis\nMongoDB\n\n2. Redis 简介Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。\nRedis 与其他 key - value 缓存产品有以下三个特点：\n\nRedis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。\nRedis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。\nRedis支持数据的备份，即master-slave模式的数据备份。\n\nRedis 优势\n\n性能极高 – Redis能读的速度是110000次&#x2F;s,写的速度是81000次&#x2F;s 。\n丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。\n原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。\n丰富的特性 – Redis还支持 publish&#x2F;subscribe, 通知, key 过期等等特性。\n\n3. 数据类型及操作Redis 的基本类型有五个: String、List、Set、Hash、Zset\nRedis 新数据类型: Bitmaps、HyperLogLog、Geospatial\n原子性\n所谓 原子 操作是指不会被线程调度机制打断的操作；\n这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。\n\n在单线程中， 能够在单条指令中完成的操作都可以认为是”原子操作”，因为中断只能发生于指令之间。\n在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。\n\nRedis 单命令的原子性主要得益于 Redis 的单线程。\nKey操作\n1234567891011keys * \t    # 查看当前库的所有keyexist key \t# 判断某个key是否存在del key\t    # 删除指定keyunlink key\t# 根据value 值进行非阻塞删除 真正的删除会在后面进行异步删除type key\t# 判断key类型expire key [10]\t# 为给定的 key 设置过期时间ttl key\t\t# 查看还有多少秒过期，-1表示永不过期，-2表示已过期select\t\t# 命令切换数据库dbsize\t\t# 查看当前数据库的 key 的数量flushdb \t# 清空当前库flushall\t# 通杀全部库\n\n\n\n\n\na. 字符串 StringString 类型是二进制安全的。意味着 Redis的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象。\nString 类型是 Redis 最基本的数据类型，一个 Redis 中字符串 value 最多可以是 512M。\n常用命令:\n123456789101112131415set &lt;key&gt;&lt;value&gt;\t\t# 添加键值对get &lt;key&gt;\t\t\t    # 查询对应键值append &lt;key&gt;&lt;value&gt;\t\t # 将给定的 &lt;value&gt; 追加到原值的末尾strlen &lt;key&gt;\t\t\t# 获得值的长度setnx &lt;key&gt;&lt;value&gt;\t\t # 只有在 key 不存在时，设置 key 的值incr &lt;key&gt;\t\t\t\t# 将 key 中储存的数字值增 1，只能对数字值操作，如果为空，新增值为 1（具有原子性）decr &lt;key&gt;\t\t\t\t# 将 key 中储存的数字值减 1，只能对数字值操作，如果为空，新增值为 -1incrby/decrby &lt;key&gt;&lt;步长&gt; \t\t\t  # 将 key 中储存的数字值增减。自定义步长mset &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt;  \t\t# 同时设置一个或多个 key-value 对mget &lt;key1&gt;&lt;key2&gt;&lt;key3&gt;...\t\t    \t# 同时获取一个或多个 valuemsetnx &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt;... \t # 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在getrange &lt;key&gt;&lt;起始位置&gt;&lt;结束位置&gt;\t\t # 获得值的范围setrange &lt;key&gt;&lt;起始位置&gt;&lt;value&gt;\t\t\t# 用 &lt;value&gt; 覆写 &lt;key&gt; 所储存的字符串值setex &lt;key&gt;&lt;过期时间&gt;&lt;value&gt;\t\t\t# 设置键值的同时，设置过期时间，单位秒。getset &lt;key&gt;&lt;value&gt;\t\t # 以新换旧，设置了新值同时获得旧值。\n\nString内部的数据结构\n内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配,不能超过512M;\nb. 列表 List单键 - 多值 数据结构\nRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。\n它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。\n\n\n常用命令\n12345678910111213141516lpush/rpush &lt;key&gt;&lt;value1&gt;&lt;value2&gt;&lt;value3&gt; ....\t# 从左边/右边插入一个或多个值。 #eg:  输入 : lpush k1 v1 v2 v3 #      &gt; lrange k1 0 -1 #     输出 ：v3 v2 v1  #     输入 : rpush k1 v1 v2 v3 #      &gt; rrange k1 0 -1 #     输出：v1 v2 v3lpop/rpop &lt;key&gt;\t\t\t\t\t# 从左边/右边吐出一个值。值在键在，值光键亡。rpoplpush &lt;key1&gt;&lt;key2&gt;\t\t\t # 从 &lt;key1&gt; 列表右边吐出一个值，插到 &lt;key2&gt; 列表左边。lrange &lt;key&gt;&lt;start&gt;&lt;stop&gt;\t\t # 按照索引下标获得元素（从左到右）lrange mylist 0 -1 0\t\t\t # 左边第一个，-1右边第一个，（0 -1表示获取所有）lindex &lt;key&gt;&lt;index&gt;\t\t\t\t # 按照索引下标获得元素（从左到右）llen &lt;key&gt;\t\t\t\t\t\t# 获得列表长度linsert &lt;key&gt; before/after &lt;value&gt;&lt;newvalue&gt;\t# 在 &lt;value&gt; 的前面/后面插入 &lt;newvalue&gt; 插入值lrem &lt;key&gt;&lt;n&gt;&lt;value&gt;\t\t\t # 从左边删除 n 个 value（从左到右）lset&lt;key&gt;&lt;index&gt;&lt;value&gt;\t\t\t # 将列表 key 下标为 index 的值替换成 value\n\nList内部数据结构\nList 的数据结构为快速链表 quickList。\n首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表。\n它将所有的元素紧挨着一起存储，分配的是一块连续的内存。\n当数据量比较多的时候才会改成 quicklist。\n因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next。\nRedis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。\n\n\n\n\nc. 集合 Set   Set 对外提供的功能与 List 类似列表的功能，特殊之处在于 Set 是可以 自动排重 的，当需要存储一个列表数据，又不希望出现重复数据时，Set 是一个很好的选择，并且 Set 提供了判断某个成员是否在一个 Set 集合内的重要接口，这个也是 List 所不能提供的。\n   Redis 的 Set 是 String 类型的无序集合。它底层其实是一个 value 为 null 的 hash 表，所以添加，删除，查找的复杂度都是 O(1)。\n一个算法，随着数据的增加，执行时间的长短，如果是 O(1)，数据增加，查找数据的时间不变。\n常用命令\n1234567891011sadd &lt;key&gt;&lt;value1&gt;&lt;value2&gt; ..... \t# 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略smembers &lt;key&gt;\t\t\t\t# 取出该集合的所有值。sismember &lt;key&gt;&lt;value&gt;\t\t # 判断集合 &lt;key&gt; 是否为含有该 &lt;value&gt; 值，有返回 1，没有返回 0scard&lt;key&gt;\t\t\t\t\t# 返回该集合的元素个数。srem &lt;key&gt;&lt;value1&gt;&lt;value2&gt; ....\t# 删除集合中的某个元素spop &lt;key&gt;\t\t\t\t\t# 随机从该集合中吐出一个值srandmember &lt;key&gt;&lt;n&gt;\t\t # 随机从该集合中取出 n 个值，不会从集合中删除smove &lt;source&gt;&lt;destination&gt;value\t# 把集合中一个值从一个集合移动到另一个集合sinter &lt;key1&gt;&lt;key2&gt;\t\t\t # 返回两个集合的交集元素sunion &lt;key1&gt;&lt;key2&gt;\t\t\t # 返回两个集合的并集元素sdiff &lt;key1&gt;&lt;key2&gt;\t\t\t # 返回两个集合的差集元素（key1 中的，不包含 key2 中的）\n\nSet的内部数据结构\nSet 数据结构是字典，字典是用哈希表实现的。\nd. 哈希 HashRedis hash 是一个键值对集合。\nRedis hash 是一个 String 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。\n注意 Redis的Hash类型和String类型的区别。\n\n\n常用命令:\n12345678hset &lt;key&gt;&lt;field&gt;&lt;value&gt;\t\t# 给 &lt;key&gt; 集合中的 &lt;field&gt; 键赋值 &lt;value&gt;hget &lt;key1&gt;&lt;field&gt;\t\t\t    # 从 &lt;key1&gt; 集合 &lt;field&gt; 取出 valuehmset &lt;key1&gt;&lt;field1&gt;&lt;value1&gt;&lt;field2&gt;&lt;value2&gt;...  # 批量设置 hash 的值hexists &lt;key1&gt;&lt;field&gt;\t\t\t# 查看哈希表 key 中，给定域 field 是否存在hkeys &lt;key&gt;\t\t\t\t# 列出该 hash 集合的所有 fieldhvals &lt;key&gt;\t\t\t\t# 列出该 hash 集合的所有 valuehincrby &lt;key&gt;&lt;field&gt;&lt;increment&gt;\t # 为哈希表 key 中的域 field 的值加上增量 1 -1hsetnx &lt;key&gt;&lt;field&gt;&lt;value&gt;\t\t # 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在\n\nHash数据结构:\nHash 类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。\n当 field-value 长度较短且个数较少时，使用 ziplist，否则使用 hashtable。\ne. 有序集合 ZsetRedis 有序集合 zset 与普通集合 set 非常相似，是一个没有重复元素的字符串集合。\n不同之处是 zset有序集合的每个成员都关联了一个评分（score）,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复的。\n因为元素是有序的，所以可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。\n访问有序集合的中间元素也是非常快的，因此能够使用有序集合作为一个没有重复成员的智能列表。\n常用命令:\n123456789zadd &lt;key&gt;&lt;score1&gt;&lt;value1&gt;&lt;score2&gt;&lt;value2&gt;…\t\t# 将一个或多个 member 元素及其 score 值加入到有序集 key 当中zrange &lt;key&gt;&lt;start&gt;&lt;stop&gt; [WITHSCORES] \t\t    # 返回有序集 key 中，下标在 &lt;start&gt;&lt;stop&gt; 之间的元素# 当带 WITHSCORES，可以让分数一起和值返回到结果集zrangebyscore key min max [withscores] [limit offset count]\t \t# 返回有序集 key 中，所有 score 值介于 min 和 max 之间（包括等于 min 或 max ）的成员。有序集成员按 score 值递增（从小到大）次序排列。zrevrangebyscore key max min [withscores] [limit offset count]   # 同上，改为从大到小排列zincrby &lt;key&gt;&lt;increment&gt;&lt;value&gt;\t\t\t# 为元素的 score 加上增量zrem &lt;key&gt;&lt;value&gt;\t\t\t\t\t   # 删除该集合下，指定值的元素zcount &lt;key&gt;&lt;min&gt;&lt;max&gt;\t\t\t\t    # 统计该集合，分数区间内的元素个数zrank &lt;key&gt;&lt;value&gt;\t\t\t\t\t   # 返回该值在集合中的排名，从 0 开始。\n\nZset内部结构:\nSortedSet（zset）是 Redis 提供的一个非常特别的数据结构，一方面它等价于 Java 的数据结构 Map&lt;String, Double&gt;，可以给每一个元素 value 赋予一个权重 score，另一方面它又类似于 TreeSet，内部的元素会按照权重 score 进行排序，可以得到每个元素的名次，还可以通过 score 的范围来获取元素的列表。\nzset 底层使用了两个数据结构\n\nhash，hash 的作用就是关联元素 value 和权重 score，保障元素 value 的唯一性，可以通过元素 value 找到相应的 score 值\n跳跃表，跳跃表的目的在于给元素 value 排序，根据 score 的范围获取元素列表\n\nf. BitmapsRedis 提供了 Bitmaps 这个数据类型 来实现位操作。\n\nBitmaps 本身不是一个数据类型,实际上是一个01字符串,但是它可以对这个字符串进行位操作。\nBitmaps 单独提供了一套指令,所以在Redis中使用Bitmaps和使用字符串方式不同, 可以把Bitmaps想象成一个以位为单位的数组,每个单位只能存储01,下标在Bitmaps中成为 偏移量。\n\n\n\n常用命令\n1234setbit &lt;key&gt; &lt;offset&gt; &lt;value&gt;\t\t# 给一个指定key的值得第offset位 赋值为value。getbit &lt;key&gt; &lt;offset&gt;\t\t\t    # 返回一个指定key的二进制信息bitcount &lt;key&gt; &lt;start&gt; &lt;offset&gt;\t\t# 返回一个指定key中位的值为1的个数(是以byte为单位不是bit)bitop &lt;operation&gt; &lt;destkey&gt; key1 key2  \t# 对key1 和key2 执行 operation 并将结果保存到 destkey\n\n主要用途\n​    主要用来存储大数据量但数据简单的操作,比如统计活跃用户量。\ng. HyperLogLogHyperLogLog是Redis的高级数据结构，它在做基数统计的时候非常有用，每个HyperLogLog的键可以计算接近 $2^{64}$ 不同元素的基数，而大小只需要12KB。\nHyperLogLog可以用很少的内存来存储集合的唯一元素。（每个HyperLogLog只有12K加上key本身的几个字节）\nHyperLogLog的结果并不精准，错误率大概在0.81%。\n常用操作\n123pfadd &lt;key&gt; &lt;element&gt;[element]  # 添加指定元素到Hyperloglog中pfcount &lt;key&gt;\t\t\t\t  # 统计key中包含的元素的个数 \tpfmerge &lt;destkey&gt; &lt;sourcekey&gt; [sourcekey] \t# 将两个或多个元素集合合并\n\n\n\n主要用途\n​    主要用来计算大量数据的基数。\nh. Geospatial​    Geo类型 是Geographic地理信息类型的缩写,该元素就是二维坐标,是地图上的经纬度。 Redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。\n常用命令\n123456geoadd key [NX|XX] [CH] longitude latitude member [longitude latitude member ...]# geoadd china:city 121.49 31.23 shanghai 添加一个位置信息geopos key member [member ...]\t\t# geopos china:city shanghai  获取一个城市的信息geodist key member1 member2 [m|km|ft|mi] # 获取两个位置之间的距离 [m|km|ft|mi] 来确定单位georadius key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] # 获取一个经纬度范围内的位置信息\n\n\n\n\n\n\n\n4. Redis 配置文件本机安装Redis时,文件的配置路径为 /etc/redis.conf\n如果使用docker由镜像生成redis容器,默认是没有配置文件的,需要自己在宿主机进行创建,然后进行配置文件挂载 /docker/redis/conf/redis.conf:/etc/redis/redis.conf \\。\n在配置文件中可以设置：\n\nUnits 单位，配置大小单位，开头定义了一些基本的度量单位，只支持 bytes，不支持 bit。大小写不敏感。\n\nINCLUDES 包含，多实例的情况可以把公用的配置文件提取出来。\n\nNETWORK 网络相关配置。\n\nbind 默认情况 bind=127.0.0.1 只能接受本机的访问请求。不写的情况下，无限制接受任何 ip 地址的访问。生产环境肯定要写你应用服务器的地址，服务器是需要远程访问的，所以需要将其注释掉。\n\nprotected-mode 如果开启了protected-mode，那么在没有设定 bind ip 且没有设密码的情况下，Redis 只允许接受本机的响应。\n\nport 端口号，默认 6379。\n\n\n\nGENERAL 通用。\n\ndaemonize 是否为后台进程，设置为 yes。\n\npidfile  存放 pid 文件的位置，每个实例会产生一个不同的 pid 文件。\n\nloglevel 指定日志记录级别，Redis 总共支持四个级别：debug、verbose、notice、warning，默认为 notice。\n\nlogfile 日志文件名称。\n\ndatabase 设定库的数量 默认16，默认数据库为 0，可以使用 SELECT &lt;dbid&gt; 命令在连接上指定数据库 id。\n\n\n\nSECURITY 安全。\n访问密码的查看、设置和取消。\n在命令中设置密码，只是临时的。重启 redis 服务器，密码就还原了。\n永久设置，需要在配置文件中进行设置。\n\nLIMITS  限制。\n\nmaxclients设置 redis 同时可以与多少个客户端进行连接。默认情况下为 10000 个客户端。\n如果达到了此限制，redis 则会拒绝新的连接请求，并且向这些连接请求方发出 max number of clients reached 以作回应。\n\nmaxmemory 建议必须设置，否则，将内存占满，造成服务器宕机。\n设置 redis 可以使用的内存量。一旦到达内存使用上限，redis 将会试图移除内部数据，移除规则可以通过 maxmemory-policy 来指定。\n如果 redis 无法根据移除规则来移除内存中的数据，或者设置了不允许移除，那么 redis 则会针对那些需要申请内存的指令返回错误信息，比如 SET、LPUSH 等。\n\nmaxmemory-policy\n\nvolatile-lru：使用 LRU 算法移除 key，只对设置了过期时间的键（最近最少使用）\n\nallkeys-lru：在所有集合 key 中，使用 LRU 算法移除 key。\n\n\n\n\n5. Redis的发布与订阅Redis 发布订阅（ pub&#x2F;sub ）是一种消息通信模式：发送者（ pub ）发送消息，订阅者（ sub ）接收消息。\nRedis 客户端可以订阅任意数量的频道。\n\n客户端可以订阅频道\n\n\n\n\n当给这个频道发布消息后，消息就会发送给订阅的客户端\n\n\n\n12subscribe channel \t\t # 订阅频道publish channel hello \t # 频道发送信息\n\n6. SpringBoot整合Redisa. 添加pom.xml 依赖\n123456789101112&lt;!-- redis --&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- spring2.X集成redis所需common-pool2--&gt;&lt;dependency&gt;  &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;  &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;  &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;\n\nb. 配置Redis\n12345678910111213141516#Redis服务器地址spring.redis.host= ip#Redis服务器连接端口spring.redis.port=6379#Redis数据库索引（默认为0）spring.redis.database= 0#连接超时时间（毫秒）spring.redis.timeout=1800000#连接池最大连接数（使用负值表示没有限制）spring.redis.lettuce.pool.max-active=20#最大阻塞等待时间(负数表示没限制)spring.redis.lettuce.pool.max-wait=-1#连接池中的最大空闲连接spring.redis.lettuce.pool.max-idle=5#连接池中的最小空闲连接spring.redis.lettuce.pool.min-idle=0\n\nc. Redis 配置类\n12345678910111213141516171819202122232425262728293031323334353637383940414243@EnableCaching@Configurationpublic class RedisConfig extends CachingConfigurerSupport &#123;    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123;        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();        RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer();        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(om);        template.setConnectionFactory(factory);\t\t\t\t// key序列化方式        template.setKeySerializer(redisSerializer);\t\t\t\t// value序列化        template.setValueSerializer(jackson2JsonRedisSerializer);\t\t\t\t// value hashmap序列化        template.setHashValueSerializer(jackson2JsonRedisSerializer);        return template;    &#125;    @Bean    public CacheManager cacheManager(RedisConnectionFactory factory) &#123;        RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer();        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\t\t\t\t// 解决查询缓存转换异常的问题        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(om);\t\t\t\t// 配置序列化（解决乱码的问题）,过期时间600秒        RedisCacheConfiguration config =           RedisCacheConfiguration.defaultCacheConfig()                .entryTtl(Duration.ofSeconds(600))      .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))                .disableCachingNullValues();        RedisCacheManager cacheManager = RedisCacheManager.builder(factory)                .cacheDefaults(config)                .build();        return cacheManager;    &#125;&#125;\n\n\n\n7. Redis事务Redis 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\nRedis 事务的主要作用就是串联多个命令防止别的命令插队。\n事务三特性\n\n单独的隔离操作\n事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n\n没有隔离级别的概念\n队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行。\n\n不保证原子性\n事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚\n\n\na. Multi、Exec、Discard从输入 Multi 命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入 Exec 后，Redis 会将之前的命令队列中的命令依次执行。\n组队的过程中可以通过 Discard 来放弃组队。\n\n\n\n\n12345678910127.0.0.1:6379&gt; multi\t\t\t\t# 开启事务OK127.0.0.1:6379(TX)&gt; set key1 val1\t # 进入队列\tQUEUED127.0.0.1:6379(TX)&gt; set key2 val2\t # 进入队列QUEUED127.0.0.1:6379(TX)&gt; exec\t\t\t# 开始执行1) OK2) OK# 开始执行之前 使用discard命令可以中断排队\n\n组队中有命令错误，队列中所有命令都不会执行\n12345678127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; set a1 b1QUEUED127.0.0.1:6379(TX)&gt; set b(error) ERR wrong number of arguments for &#x27;set&#x27; command127.0.0.1:6379(TX)&gt; exec(error) EXECABORT Transaction discarded because of previous errors.\n\n组队中不报错，执行时报错,只有报错的命令会被取消。\n123456789127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; set vas sdadQUEUED127.0.0.1:6379(TX)&gt; incr vasQUEUED127.0.0.1:6379(TX)&gt; exec1) OK2) (error) ERR value is not an integer or out of range\n\n\n\nb. 事务冲突多个事务对同一数据进行操作时可能出现冲突。\n1. 悲观锁悲观锁（Pessimistic Lock），即每次去拿数据的时候都认为有其他线程会修改，所以每次在拿数据的时候都会上锁，这样其他线程想要拿到这个数据就会被 block 直到成功拿到锁。（效率低）\n一个事务执行时，其他对同一数据进行操作的事务都不能执行。\n2. 乐观锁乐观锁（Optimistic Lock），即每次去拿数据的时候都认为其他线程不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间有没有其他线程去更新这个数据，可以使用版本号等机制。\n乐观锁适用于多读的应用类型，这样可以提高吞吐量。\nRedis 就是利用这种 check-and-set 机制实现事务的。\n3. Watch、unwatch在执行 multi 之前，先执行 watch key1 [key2]，可以监视一个（或多个 ）key 。如果在事务执行之前这个 key 被其他命令所改动，那么事务将被打断。\n取消 WATCH 命令对所有 key 的监视。如果在执行 WATCH 命令之后，EXEC 命令或 DISCARD 命令先被执行，那么就不需要再执行 UNWATCH 。\n8. 持久化将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。\na. RDB(Redis DataBase)在指定的 时间间隔内 将内存汇总的数据集快照写入磁盘。 即 Snapshot 快照，恢复时是将快照文件直接读到内存里。\n备份过程\nRedis 会单独创建一个子进程（fork）来进行持久化。\n先将数据写入到一个临时文件中，待持久化过程完成后，再将这个临时文件内容覆盖到 dump.rdb。\n整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。\nRDB 的缺点是最后一次持久化后的数据可能丢失。\nFork子进程\n\n作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程\n在 Linux 程序中，fork() 会产生一个和父进程完全相同的子进程，但子进程在此后多会 exec 系统调用，出于效率考虑，Linux 中引入了 写时复制技术\n一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程\n\n和RDB有关的配置\n\n临时文件名设置。  在 redis.conf 中配置文件名称，默认为 dump.rdb。\n\n临时文件保存位置。  rdb 文件的保存路径可以修改。默认为 Redis 启动时命令行所在的目录下。\n\nstop-writes-on-bgsave-error   即当 redis 无法写入磁盘，关闭 redis 的写入操作。\n\nrdbcompression    持久化的文件是否进行压缩存储。\n\nrdbchecksum   完整性的检查，即数据是否完整性、准确性。\n\nsave   表示达到什么操作数时进行备份。\n1save 60 10000  # 表示 如果60s内 超过 10000个keys改变过,那么触发持久化\n\n优点\n\n适合大规模的数据恢复；\n对数据完整性和一致性要求不高更适合使用；\n节省磁盘空间；\n恢复速度快。\n\n缺点\n\nFork 的时候，内存中的数据被克隆了一份，大致 2 倍的膨胀性需要考虑；\n虽然 Redis 在 fork 时使用了**写时拷贝技术**，但是如果数据庞大时还是比较消耗性能；\n在备份周期在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改。\n\nRBD的备份过程\n​    只需要将 要备份的rdb文件拷贝到备份文件的默认目录下,启动redis即可自动将rdb文件恢复。\nb. AOF(Append Of File)以日志的形式来记录每个写操作（增量保存），将 Redis 执行过的所有写指令记录下来（读操作不记录）， 只许追加文件但不可以改写文件，Redis 启动之初会读取该文件重新构建数据。\n如果 Redis 重启就会根据日志文件（如果AOF文件和RDB文件都存在，优先恢复AOF）的内容将写指令从前到后执行一次以完成数据的恢复工作。\nAOF默认不开启。在配置文件中设置 appendonly yes 打开\n执行流程\n\n客户端的请求写命令会被 append 追加到 AOF 缓冲区内；\nAOF 缓冲区根据 AOF 持久化策略 [always,everysec,no] 将操作 sync 同步到磁盘的 AOF 文件中；\nAOF 文件大小超过重写策略或手动重写时，会对 AOF 文件 Rewrite 重写，压缩 AOF 文件容量；\nRedis 服务重启时，会重新 load 加载 AOF 文件中的写操作达到数据恢复的目的。\n\nAOF 和 RDB 同时开启时，系统默认读取 AOF 的数据（数据不会存在丢失）\n和AOF有关的配置\n\nappendfsync always  时钟同步，每次 Redis 的写入都会立刻记入日志；性能较差但数据完整性比较好。\nappendfsync everysec  每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。\nappendfsync no Redis 不主动进行同步，把同步时机交给操作系统。\nRewrite 压缩当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令 bgrewriteaof。\n\nAOF 修复\n当AOF文件出错时,可以使用 redis-check-aof--fix [文件名] 命令对AOF文件进行修复。\nAOF优势\n\n备份机制更稳健，丢失数据概率更低；\n可读的日志文本，通过操作 AOF 稳健，可以处理误操作。\n\nAOF缺点\n\n比起 RDB 占用更多的磁盘空间；\n恢复备份速度要慢；\n每次读写都同步的话，有一定的性能压力；\n存在个别 Bug，造成不能恢复。\n\nc. AOF和RDB的选择官方推荐两个都启用。\n如果对数据不敏感，可以选单独用 RDB。\n不建议单独用 AOF，因为可能会出现 Bug。\n如果只是做纯内存缓存，可以都不用。\n9. Redis 主从复制主机数据更新后根据配置和策略， 自动同步到备机的 master&#x2F;slaver 机制，Master 以写为主，Slaver 以读为主。\n\n\n主从复制的优势\n\n读写分离，性能扩展\n容灾快速恢复\n一主多从！\n\na. 模拟一主两从复制我自己通过Docker模拟实现。\n\n为每个redis容器创建自己的redis.conf文件\n\n先创建一个公用的redis.conf\n12345678# daemonize yesdir /datalogfile /data/redis.logprotected-mode no#注释掉，可以远程访问#bind 127.0.0.1#开启AOFappendonly no\n\n然后分别创建 redis6370.conf redis6371.conf redis6372.conf,写入对应的配置信息。\n1234include /redis-cluster/redis.confpidfile /var/run/redis_6370.pidport 6370dbfilename dump6370.rdb\n\n\n启动三个Redis容器，加载对应的conf文件\n\ndocker run -itd -p 6370:6379 -v /home/redis/redis.conf:/redis-cluster/redis6370.conf -v /home/redis/data/:/data --name redis6370 -e &quot;TZ=Asia/Shanghai&quot; redis  /redis-cluster/redis6370.conf\n123- ```sh  docker run -itd -p 6371:6379 -v /home/redis/redis.conf:/redis-cluster/redis6371.conf -v /home/redis/data/:/data --name redis6371 -e &quot;TZ=Asia/Shanghai&quot; redis  /redis-cluster/redis6371.conf\n\n\n&#96;&#96;&#96;shdocker run -itd -p 6372:6379 -v &#x2F;home&#x2F;redis&#x2F;redis.conf:&#x2F;redis-cluster&#x2F;redis6372.conf -v &#x2F;home&#x2F;redis&#x2F;data&#x2F;:&#x2F;data –name redis6372 -e “TZ&#x3D;Asia&#x2F;Shanghai” redis  &#x2F;redis-cluster&#x2F;redis6372.conf\n12345678910111213141516173. 随便进入一个redis进程,查看主从信息,发现三个都是主节点   ```sh   127.0.0.1:6379&gt; info replication   # Replication   role:master\t\t\t# 主机   connected_slaves:0\t # 没有slave节点   master_failover_state:no-failover   master_replid:1215d3dd30318947c9fbb130adb781e5e250bac5   master_replid2:0000000000000000000000000000000000000000   master_repl_offset:0   second_repl_offset:-1   repl_backlog_active:0   repl_backlog_size:1048576   repl_backlog_first_byte_offset:0   repl_backlog_histlen:0\n\n\n配置主从关系\n1slaveof [IP] [Port] # 将当前redis服务 作为从机备份到 [ip]:[port]\n\n由于此处使用的是docker,所以得先查看主机的docker的IP地址\n123456789101112131415161718docker inspect [容器名 redis6370]&quot;Networks&quot;: &#123;    &quot;bridge&quot;: &#123;        &quot;IPAMConfig&quot;: null,        &quot;Links&quot;: null,        &quot;Aliases&quot;: null,        &quot;NetworkID&quot;: &quot;a4b86cbe5c82a4651588bb950df3cd42cd8391bffba939ac5fc43858d1f2be37&quot;,        &quot;EndpointID&quot;: &quot;052a96ffb53bdf74a7322adfceba70248f17394a9697951e6d78f21f5bf0b72f&quot;,        &quot;Gateway&quot;: &quot;172.17.0.1&quot;,        &quot;IPAddress&quot;: &quot;172.17.0.8&quot;,        &quot;IPPrefixLen&quot;: 16,        &quot;IPv6Gateway&quot;: &quot;&quot;,        &quot;GlobalIPv6Address&quot;: &quot;&quot;,        &quot;GlobalIPv6PrefixLen&quot;: 0,        &quot;MacAddress&quot;: &quot;02:42:ac:11:00:08&quot;,        &quot;DriverOpts&quot;: null    &#125;&#125;\n\n查看 主机6370 和 从机6371&#x2F;2 对应的信息\n1234567891011121314151617# 6371 和 6372 作为 6370的从机# 6370127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2   # 得到两个从服务器slave0:ip=172.17.0.10,port=6379,state=online,offset=602,lag=1slave1:ip=172.17.0.9,port=6379,state=online,offset=602,lag=1master_failover_state:no-failovermaster_replid:46570ab087353ccfb3b0314f18f2f2a3cfa6a31fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:602second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:602\n\n123456789101112131415161718192021222324# 6371/2127.0.0.1:6379&gt; info replication# Replicationrole:slave\t\t# 角色为从机master_host:172.17.0.8\t# 主机为6370master_port:6379master_link_status:upmaster_last_io_seconds_ago:3master_sync_in_progress:0slave_read_repl_offset:1050slave_repl_offset:1050slave_priority:100slave_read_only:1replica_announced:1connected_slaves:0master_failover_state:no-failovermaster_replid:46570ab087353ccfb3b0314f18f2f2a3cfa6a31fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:1050second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:547repl_backlog_histlen:504\n\n在从机上写数据会报错\n123# 6371127.0.0.1:6379&gt; set k1 a(error) READONLY You can&#x27;t write against a read only replica.\n\n\n\nb. 主从复制原理\nslave 启动成功连接到 master 后会发送一个 sync 命令（同步命令）。\nmaster 接到命令启动后台的存盘进程，对数据进行持久化操作，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master 将传送整个数据文件（rdb）到 slave，以完成一次完全同步。\n当主服务进行写操作后，和从服务器进行数据同步。\n全量复制：而 slave 服务在接收到数据库文件数据后，将其存盘并加载到内存中。\n增量复制：master 继续将新的所有收集到的修改命令依次传给 slave，完成同步。\n只要是重新连接 master，一次完全同步（全量复制）将被自动执行。\n\nc. 主从复制常用方式1. 一主两仆主机为6370 从机 6371和6372;两个从机平等的作为一个主机的从机。\n从机挂掉\n当从机6371挂掉,重启后,6371不再作为6370的主机,而是作为新的master\n当再次把6380作为6379的从机加入后，从机 会把数据从头到尾复制。\n主机挂掉 \n6371和6372仍然是6370的从机，不会做任何事；当6370重启后，既然是主服务器。\n2. 薪火相传\n\n上一个 slave 可以是下一个 slave 的 master，slave 同样可以接收其他 slave的连接和同步请求，那么该 slave 作为了链条中下一个的 master，可以有效减轻 master 的写压力，去中心化降低风险。\n中途变更转向：会清除之前的数据，重新建立拷贝最新的。\n当某个 slave 宕机，后面的 slave 都没法备份。\n即当主机挂掉，从机还是从机，但是无法继续写数据。\n3. 反客为主 当一个 master 宕机后，后面的 slave 可以立刻升为 master，其后面的 slave 不用做任何修改。手动完成。\n1slaveof no one\n\n\n\nd. 哨兵模式哨兵模式自动实现主从切换，而上面的反客为主需要手动完成。\n能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。\n当主机宕机后,会在从机中选举新的主机\n选举规则\n\n根据优先级别，slave-priority&#x2F;replica-priority，优先选择优先级靠前的。\n\n\n根据偏移量，优先选择偏移量大的。\n\n根据 runid，优先选择最小的服务。\n\n\n复制延时\n由于所有的写操作都是先在 master 上操作，然后同步更新到 slave 上，所以从 master 同步到 slave 从机有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave 机器数量的增加也会使这个问题更加严重。\n设置哨兵模式的方法\n\n创建 sentinel.conf 文件\n\n1/opt/etc/sentinel.conf\n\n\n配置哨兵\n\n123sentinel monitor mymaster 172.16.88.168 6379 1# mymaster：监控对象起的服务器名称# 1：至少有多少个哨兵同意迁移的数量。 \n\n\n启动哨兵\n\n1redis-sentinel  /opt/etc/sentinel.conf \n\n\n\n10. Redis 集群集群需要解决的问题\n容量不够，redis 如何进行扩容？\n并发写操作， redis 如何分摊？\n主从模式，薪火相传模式，主机宕机，导致 ip 地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。\n解决方案\n\n代理主机\n\n\n无中心化集群配置\n\n\n\n\n\n\nRedis 集群实现了对 Redis 的水平扩容，即启动 N 个 Redis 节点，将整个数据库分布存储在这 N 个节点中，每个节点存储总数据的 1&#x2F;N 。\nRedis 集群通过分区（partition）来提供一定程度的可用性（availability），即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。\na. 搭建Redis集群搭建一个由三对主从服务器组成的redis集群,共六个redis服务器。\n\n创建六个redis服务的conf文件\n六个服务的主从端口号为：6370-6380 6371-6381 6372-6382\n123456789[root@VM-4-9-centos redis-cluster]# lltotal 32-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6370.conf-rw-r--r-- 1 root root 183 Mar 23 19:38 redis6371.conf-rw-r--r-- 1 root root 183 Mar 23 19:38 redis6372.conf-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6380.conf-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6381.conf-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6382.conf-rw-r--r-- 1 root root 142 Mar 23 19:27 redis.conf\n\n配置文件内容为:\n1234567include /redis-cluster/redis.confpidfile /var/run/redis_6370.pidport 6370dbfilename dump6370.rdbcluster-enabled yescluster-config-file node6370.confcluster-node-timeout 15000\n\n启动六个redis服务器\n启动命令为:\n12# 此处以6380为例,其他以此类推docker run -itd -p 6380:6379 -v /home/redis/redis.conf:/redis-cluster/redis6380.conf -v /home/redis/data/:/data --name redis6380 -e &quot;TZ=Asia/Shanghai&quot; redis  /redis-cluster/redis6380.conf\n\n12345678[root@VM-4-9-centos redis-cluster]# docker psCONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS                                                  NAMESc0ddd1a17009   redis         &quot;docker-entrypoint.s…&quot;   4 seconds ago    Up 4 seconds    0.0.0.0:6380-&gt;6379/tcp, :::6380-&gt;6379/tcp              redis6380677f6d098415   redis         &quot;docker-entrypoint.s…&quot;   29 seconds ago   Up 28 seconds   0.0.0.0:6381-&gt;6379/tcp, :::6381-&gt;6379/tcp              redis6381cf71e9f7f3cf   redis         &quot;docker-entrypoint.s…&quot;   2 minutes ago    Up 2 minutes    0.0.0.0:6382-&gt;6379/tcp, :::6382-&gt;6379/tcp              redis63827657bb60a3ec   redis         &quot;docker-entrypoint.s…&quot;   2 minutes ago    Up 2 minutes    0.0.0.0:6372-&gt;6379/tcp, :::6372-&gt;6379/tcp              redis6372e48e4d898b90   redis         &quot;docker-entrypoint.s…&quot;   3 minutes ago    Up 3 minutes    0.0.0.0:6371-&gt;6379/tcp, :::6371-&gt;6379/tcp              redis637179232aef9947   redis         &quot;docker-entrypoint.s…&quot;   4 minutes ago    Up 4 minutes    0.0.0.0:6370-&gt;6379/tcp, :::6370-&gt;6379/tcp              redis6370\n\n查看docker中,各个redis服务的IP地址,记录下来\n123456docker inspect redis6370  \t# 172.17.0.8docker inspect redis6371  \t# 172.17.0.9docker inspect redis6372  \t# 172.17.0.10docker inspect redis6380  \t# 172.17.0.12docker inspect redis6381  \t# 172.17.0.7docker inspect redis6382  \t# 172.17.0.11\n\n进入某一容器中,使用集群搭建命令\n12# 执行redis-cli --cluster create --cluster-replicas 1 172.17.0.8:6370 172.17.0.9:6371 172.16.88.168:6381 172.16.88.168:6389 172.16.88.168:6390 172.16.88.168:6391\n\nredis cluster 如何分配这六个节点?\n一个集群至少要有三个主节点。\n选项 --cluster-replicas 1，表示希望为集群中的每个主节点创建一个从节点。\n分配原则 尽量保证每个主数据库运行在不同的 IP 地址，每个从库和主库不在一个 IP 地址上。\n\n\n\n\n*什么是 slots？*\n一个 Redis 集群包含 16384 个插槽（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个。\n集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。\n集群中的每个节点负责处理一部分插槽。 例如， 如果一个集群可以有主节点， 其中：\n\n节点 A 负责处理 0 号至 5460 号插槽。\n节点 B 负责处理 5461 号至 10922 号插槽。\n节点 C 负责处理 10923 号至 16383 号插槽。\n\n如何在集群中录入值？\n在 redis-cli 每次录入、查询键值，redis 都会计算出该 key 应该送往的插槽，如果不是该客户端对应服务器的插槽，redis 会报错，并告知应前往的 redis 实例地址和端口。\nredis-cli 客户端提供了 –c 参数实现自动重定向。\n例如 redis-cli -c –p 6379 登入后，再录入、查询键值对可以自动重定向。\n如何查询集群中的值？\n每个主机只能查询自己范围内部的插槽。\ncluster keyslot &lt;key&gt;：查询某个 key 的 slot。\ncluster countkeysinslot &lt;slot&gt;：查询某个 slot 是否有值。\nCLUSTER GETKEYSINSLOT &lt;slot&gt;&lt;count&gt;：返回 count 个 slot 槽中的键。\n故障恢复\n如果主节点下线？从节点能否自动升为主节点？注意：15 秒超时。\n\n当 6379 挂掉后，6389 成为新的主机。\n\n主节点恢复后，主从关系会如何？主节点回来变成从机。\n\n当 6379 重启后，6379 成为 6389 的从机。\n\n如果所有某一段插槽的主从节点都宕掉，redis 服务是否还能继续?\n\n如果某一段插槽的主从都挂掉，而 cluster-require-full-coverage&#x3D;yes，那么 ，整个集群都挂掉。\n如果某一段插槽的主从都挂掉，而 cluster-require-full-coverage&#x3D;no，那么，该插槽数据全都不能使用，也无法存储。\n\n1redis.conf` 中的参数 `cluster-require-full-coverage\n\n\n\nb. 集群优点\n实现扩容；\n分摊压力；\n无中心配置相对简单。\n\nc. 集群缺点\n多键操作是不被支持的；\n多键的 Redis 事务是不被支持的。lua 脚本不被支持；\n由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大\n\n11. Redis 应用问题a. 缓存穿透\n\n现象\nkey 对应的数据在数据源并不存在，每次针对此 key 的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。\n比如用一个不存在的用户 id 获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。\n造成：\n\n应用服务器压力变大。\nredis 命中率下降 –&gt; 一直查询数据库 。\n\n如何解决\n\n对空值缓存\n如果一个查询返回的数据为空（不管是数据是否不存在），仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。\n\n设置可访问的名单（白名单）：\n使用 bitmaps 类型定义一个可以访问的名单，名单 id 作为 bitmaps 的偏移量，每次访问和 bitmap 里面的 id 进行比较，如果访问 id 不在 bitmaps 里面，进行拦截，则不允许访问。\n\n采用布隆过滤器\n布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量（位图）和一系列随机映射函数（哈希函数）。\n布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。\n将所有可能存在的数据哈希到一个足够大的 bitmaps 中，一个一定不存在的数据会被这个 bitmaps 拦截掉，从而避免了对底层存储系统的查询压力。\n\n进行实时监控\n当发现 Redis 的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。\n\n\nb.  缓存击穿\n\nkey 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。\n\n数据库访问压力瞬间增大。\nredis 中没有出现大量 key 过期，redis 正常运行。\n某个经常访问的 key 过期，突然有大量访问这个数据\n\n如何解决\n\n预先设置热门数据\n在 redis 高峰访问之前，把一些热门数据提前存入到 redis 里面,加大这些热门数据 key 的时长。\n\n实时调整\n现场监控哪些数据热门，实时调整 key 的过期时长。\n\n使用锁\n效率会降低\n\n\nc. 缓存雪崩\n\nkey 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。\n缓存雪崩与缓存击穿的区别在于这里针对很多 key 缓存，前者则是某一个 key。\n\n数据库压力变大。\n即极少的时间段，查询大量 key 的集中过期情况。\n\n如何解决\n\n构建多级缓存架构****\nnginx 缓存 + redis 缓存 + 其他缓存（ehcache等）\n\n使用锁或队列：\n用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况。\n\n设置过期标志更新缓存：\n记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。\n\n将缓存失效时间分散开：\n比如我们可以在原有的失效时间基础上增加一个随机值，比如 1～5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n\n\n12. 分布式锁​    随着计算机系统规模的发展,分布式系统越来越多的被应用到商业中。由于分布式系统分布在不同的机器上，将使原有的单机情况下的并发控制锁策略失效，单冲的Java API 并没有提供分布式锁的能力，为了解决这个问题，就需要一种垮JVM的互斥机制来控制共享资源的访问。\n主流的分布式锁解决方案\n\n基于数据库实现分布式锁\n基于缓存实现分布式锁，性能最高\n基于Zookeeper，可靠性最高\n\na. 基于Redis的分布式锁实现1. setnxredis中可以使用 setnx 来设置一个带锁的键值对,加锁期间其他的人无法进行修改。\n为了防止一直加锁,可以使用expire设置过期时间。del来删除锁\n为了防止设置过期时间的时候就出现异常,导致设置失败,可以在set的同时进行加锁,并同时设置过期时间。\n12345678910111213141516171819202122232425262728293031127.0.0.1:6379&gt; setnx user k1  # 设置带锁的user(integer) 1127.0.0.1:6379&gt; setnx user k2  # 锁没释放,无法再次设置\t(integer) 0127.0.0.1:6379&gt; setnx user k3(integer) 0127.0.0.1:6379&gt; del user\t   # 删除锁\t(integer) 1127.0.0.1:6379&gt; setnx user k3   # 就可以再次设置\t(integer) 1127.0.0.1:6379&gt; expire user 10\t# 可以设置过期时间(integer) 1127.0.0.1:6379&gt; ttl user(integer) 7127.0.0.1:6379&gt; ttl user(integer) 6127.0.0.1:6379&gt; ttl user(integer) 1127.0.0.1:6379&gt; ttl user \t# 过期(integer) -2# 为了防止设置过期时间的时候就出现异常,导致设置失败,可以在set的同时进行加锁,并设置过期时间127.0.0.1:6379&gt; set k2 v2 nx ex 12OK127.0.0.1:6379&gt; get k2&quot;v2&quot;127.0.0.1:6379&gt; ttl k2(integer) 6127.0.0.1:6379&gt; ttl k2(integer) 4127.0.0.1:6379&gt; ttl k2(integer) 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Redis","date":"2022-04-07T05:26:46.000Z","categories_index":"互联网八股","tags_index":"分布式缓存,Redis","author_index":"张 凡"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post1$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server1$ hexo server\n\nMore info: Server\nGenerate static files1$ hexo generate\n\nMore info: Generating\nDeploy to remote sites1$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-04-07T02:07:52.961Z","categories_index":"","tags_index":"","author_index":"张 凡"}]