[{"id":"7f77c660cadf02b64dd36120e903f5f0","title":"Mysql","content":"1. 概述\n\n\n\n\n\n\n\n\n MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。\n\n\n一条SQL语句的执行流程如下:\n\n建立连接。先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n\n如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。\n如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n\n\n查询缓存。连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\n​    MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之**前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。&#96;key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n​    查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表。\n需要注意的是，&#96;MySQL 8.0 版本直接将查询缓存的整块功能删掉了**，也就是说 8.0 开始彻底没有这个功能了。\n\n\n语法分析。如果没有命中查询缓存，就要开始真正执行语句了。\n首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n\n\n语法优化。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n所有的现代数据库都在用基于成本的优化（即CBO）来优化查询。道理是针对每个运算设置一个成本，通过应用成本最低廉的一系列运算，来找到最佳的降低查询成本的方法。对于联接操作，我会专注于它们的时间复杂度，但是，数据库优化器计算的是它们的 CPU 成本、磁盘 I&#x2F;O 成本、和内存需求。\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。\n\n\n&#96;SQl执行**。\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限。\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n1mysql&gt; select * from T where ID=10;\n\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n\n调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n至此，这个语句就执行完成了。\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n\n\n日志记录。日志记录是数据的一个重要组成部分，这是DBA进行恢复，查错，优化的主要依据。\n日志记录在更新操作上显得尤为重要，Mysql有两个主要日志：&#96;redo log（重做日志）和 binlog（归档日志）**\na. redo Log\n举个例子来介绍一下日志的记录方式，如果有人要赊账或者还账的话，掌柜一般有两种做法：\n\n一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；\n另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。\n\n在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。\n这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。\n​    而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 &#96;WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。**\n​    当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。\n​    InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。\n\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。\nb. BinLog\n​    上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n​    最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。\n这两种日志有以下三点不同。\n\nredo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\nredo log 是物理日志**，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志**，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。\nredo log 是循环写的，空间固定会用完**；binlog 是可以追加写入的**。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n以一条更新或插入记录为例,日志的写过程如下:\n\n引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n执行器调用引擎的提交事务接口，引擎把刚刚写入的 &#96;redo log 改成提交（commit）状态**，更新完成。\n\n将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是****”两阶段提交”****。\n为什么必须有“两阶段提交”呢？\n这是为了让两份日志之间的逻辑一致。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。如果当一个日志写完之后,而另外一个未写完,那么就会造成数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。\n\n\n2. 事务隔离事务的四个特性: ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）\n\n原子性: 事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。\n回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。\n\n一致性: 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。\n\n隔离性: 一个事务所做的修改在最终提交以前，对其它事务是不可见的。\n\n持久性: 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。\n可以通过数据库备份和恢复来实现，在系统发生崩溃时，使用备份的数据库进行数据恢复。\n\n\n\n主要讲事务的隔离性。\n​    隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。&#96;SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。**\n\n读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。\n读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。\n这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n为什么建议你尽量不要使用长事务。\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n实现事务隔离的原理InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。\nInnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。\n\n对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n\n而当前读，总是读取已经提交完成的最新版本。\n你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\n3. 索引索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。\na. 哈希表\n哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。\nb. 有序数组\n有序数组在等值查询和范围查询场景中的性能就都非常优秀。如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。\n有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。\nc. 搜索树\n二叉搜索树的查询复杂度是 $O(log_2(N))$ ，为了保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。 二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。\n为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。\n以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\na. InnoDB 的索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，&#96;InnoDB 使用了 B+ 树索引模型**，所以数据都是存储在 B+ 树中的。\n索引类型分为主键索引和非主键索引。\n主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？\n\n如果语句是 select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；\n如果语句是 select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。\n\n主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。\n1. 覆盖索引由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？\n也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n2. 最左前缀B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。关于最左前缀,看下面这个例子:\n\n\n\n当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。\n如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。\n\n\n3. 索引下推在不得不回表时,如果查询语句对联合索引上的其他字段有特别约束,可以先进行筛选再回表。\nb. 索引选择和实践普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。\n当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。\n在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。\n创建索引可以使用的方式有：\n\n直接创建完整索引，这样可能比较占用空间；\n创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。\n4. 锁根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。\n应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。\n但是加锁需要消耗资源，锁的各种操作(包括获取锁、释放锁、以及检查锁状态)都会增加系统开销。因此封锁粒度越小，系统开销就越大。\n在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。\na. 全局锁全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 &#96;Flush tables with read lock (FTWRL)**。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的写语句会被阻塞。\n全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。\n以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。\n但是让整库都只读，听上去就很危险：\n\n如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\nb. 表级锁MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。\n表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n另一类表级的锁是 MDL（metadata lock)。&#96;MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。**你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n\n读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\nc. 行锁MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。\n1. 两阶段锁加锁和解锁分为两个阶段进行。\n在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n两段锁协议可能会造成死锁。\n我们可以主动进行死锁检测，主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。死锁检测要耗费大量的 CPU 资源。\n减少死锁的方案：\n\n如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。\n\n控制并发度\n\n将一行改成逻辑上的多行来减少锁冲突。\n\n\n","slug":"Mysql","date":"2022-04-07T06:17:50.000Z","categories_index":"","tags_index":"数据库,Mysql","author_index":"张 凡"},{"id":"d1660779e842dc0a9949e0b888a18409","title":"Reids","content":"1. NoSQLNoSQL（ NoSQL &#x3D; Not Only SQL ），意即不仅仅是 SQL，泛指非关系型的数据库。\nNoSQL 不依赖业务逻辑方式存储，而以简单的 key-value 模式存储。因此大大的增加了数据库的扩展能力。\n\n不遵循 SQL 标准。\n不支持 ACID。\n远超于 SQL 的性能。\n\n适用于的场景\n\n对数据高并发的读写；\n海量数据的读写；\n对数据高可扩展性的。\n\n不适用的场景\n\n需要事务支持；\n基于 sql 的结构化查询存储，处理复杂的关系，需要即席查询。\n\n常见的 NoSQL 数据库\n\nRedis\nMongoDB\n\n2. Redis 简介Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。\nRedis 与其他 key - value 缓存产品有以下三个特点：\n\nRedis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。\nRedis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。\nRedis支持数据的备份，即master-slave模式的数据备份。\n\nRedis 优势\n\n性能极高 – Redis能读的速度是110000次&#x2F;s,写的速度是81000次&#x2F;s 。\n丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。\n原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。\n丰富的特性 – Redis还支持 publish&#x2F;subscribe, 通知, key 过期等等特性。\n\n3. 数据类型及操作Redis 的基本类型有五个: String、List、Set、Hash、Zset\nRedis 新数据类型: Bitmaps、HyperLogLog、Geospatial\n原子性\n所谓 原子 操作是指不会被线程调度机制打断的操作；\n这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。\n\n在单线程中， 能够在单条指令中完成的操作都可以认为是”原子操作”，因为中断只能发生于指令之间。\n在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。\n\nRedis 单命令的原子性主要得益于 Redis 的单线程。\nKey操作\n1234567891011keys * \t    # 查看当前库的所有keyexist key \t# 判断某个key是否存在del key\t    # 删除指定keyunlink key\t# 根据value 值进行非阻塞删除 真正的删除会在后面进行异步删除type key\t# 判断key类型expire key [10]\t# 为给定的 key 设置过期时间ttl key\t\t# 查看还有多少秒过期，-1表示永不过期，-2表示已过期select\t\t# 命令切换数据库dbsize\t\t# 查看当前数据库的 key 的数量flushdb \t# 清空当前库flushall\t# 通杀全部库\n\n\n\n\n\na. 字符串 StringString 类型是二进制安全的。意味着 Redis的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象。\nString 类型是 Redis 最基本的数据类型，一个 Redis 中字符串 value 最多可以是 512M。\n常用命令:\n123456789101112131415set &lt;key&gt;&lt;value&gt;\t\t# 添加键值对get &lt;key&gt;\t\t\t    # 查询对应键值append &lt;key&gt;&lt;value&gt;\t\t # 将给定的 &lt;value&gt; 追加到原值的末尾strlen &lt;key&gt;\t\t\t# 获得值的长度setnx &lt;key&gt;&lt;value&gt;\t\t # 只有在 key 不存在时，设置 key 的值incr &lt;key&gt;\t\t\t\t# 将 key 中储存的数字值增 1，只能对数字值操作，如果为空，新增值为 1（具有原子性）decr &lt;key&gt;\t\t\t\t# 将 key 中储存的数字值减 1，只能对数字值操作，如果为空，新增值为 -1incrby/decrby &lt;key&gt;&lt;步长&gt; \t\t\t  # 将 key 中储存的数字值增减。自定义步长mset &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt;  \t\t# 同时设置一个或多个 key-value 对mget &lt;key1&gt;&lt;key2&gt;&lt;key3&gt;...\t\t    \t# 同时获取一个或多个 valuemsetnx &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt;... \t # 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在getrange &lt;key&gt;&lt;起始位置&gt;&lt;结束位置&gt;\t\t # 获得值的范围setrange &lt;key&gt;&lt;起始位置&gt;&lt;value&gt;\t\t\t# 用 &lt;value&gt; 覆写 &lt;key&gt; 所储存的字符串值setex &lt;key&gt;&lt;过期时间&gt;&lt;value&gt;\t\t\t# 设置键值的同时，设置过期时间，单位秒。getset &lt;key&gt;&lt;value&gt;\t\t # 以新换旧，设置了新值同时获得旧值。\n\nString内部的数据结构\n内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配,不能超过512M;\nb. 列表 List单键 - 多值 数据结构\nRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。\n它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。\n\n\n常用命令\n12345678910111213141516lpush/rpush &lt;key&gt;&lt;value1&gt;&lt;value2&gt;&lt;value3&gt; ....\t# 从左边/右边插入一个或多个值。 #eg:  输入 : lpush k1 v1 v2 v3 #      &gt; lrange k1 0 -1 #     输出 ：v3 v2 v1  #     输入 : rpush k1 v1 v2 v3 #      &gt; rrange k1 0 -1 #     输出：v1 v2 v3lpop/rpop &lt;key&gt;\t\t\t\t\t# 从左边/右边吐出一个值。值在键在，值光键亡。rpoplpush &lt;key1&gt;&lt;key2&gt;\t\t\t # 从 &lt;key1&gt; 列表右边吐出一个值，插到 &lt;key2&gt; 列表左边。lrange &lt;key&gt;&lt;start&gt;&lt;stop&gt;\t\t # 按照索引下标获得元素（从左到右）lrange mylist 0 -1 0\t\t\t # 左边第一个，-1右边第一个，（0 -1表示获取所有）lindex &lt;key&gt;&lt;index&gt;\t\t\t\t # 按照索引下标获得元素（从左到右）llen &lt;key&gt;\t\t\t\t\t\t# 获得列表长度linsert &lt;key&gt; before/after &lt;value&gt;&lt;newvalue&gt;\t# 在 &lt;value&gt; 的前面/后面插入 &lt;newvalue&gt; 插入值lrem &lt;key&gt;&lt;n&gt;&lt;value&gt;\t\t\t # 从左边删除 n 个 value（从左到右）lset&lt;key&gt;&lt;index&gt;&lt;value&gt;\t\t\t # 将列表 key 下标为 index 的值替换成 value\n\nList内部数据结构\nList 的数据结构为快速链表 quickList。\n首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表。\n它将所有的元素紧挨着一起存储，分配的是一块连续的内存。\n当数据量比较多的时候才会改成 quicklist。\n因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next。\nRedis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。\n\n\n\n\nc. 集合 Set   Set 对外提供的功能与 List 类似列表的功能，特殊之处在于 Set 是可以 自动排重 的，当需要存储一个列表数据，又不希望出现重复数据时，Set 是一个很好的选择，并且 Set 提供了判断某个成员是否在一个 Set 集合内的重要接口，这个也是 List 所不能提供的。\n   Redis 的 Set 是 String 类型的无序集合。它底层其实是一个 value 为 null 的 hash 表，所以添加，删除，查找的复杂度都是 O(1)。\n一个算法，随着数据的增加，执行时间的长短，如果是 O(1)，数据增加，查找数据的时间不变。\n常用命令\n1234567891011sadd &lt;key&gt;&lt;value1&gt;&lt;value2&gt; ..... \t# 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略smembers &lt;key&gt;\t\t\t\t# 取出该集合的所有值。sismember &lt;key&gt;&lt;value&gt;\t\t # 判断集合 &lt;key&gt; 是否为含有该 &lt;value&gt; 值，有返回 1，没有返回 0scard&lt;key&gt;\t\t\t\t\t# 返回该集合的元素个数。srem &lt;key&gt;&lt;value1&gt;&lt;value2&gt; ....\t# 删除集合中的某个元素spop &lt;key&gt;\t\t\t\t\t# 随机从该集合中吐出一个值srandmember &lt;key&gt;&lt;n&gt;\t\t # 随机从该集合中取出 n 个值，不会从集合中删除smove &lt;source&gt;&lt;destination&gt;value\t# 把集合中一个值从一个集合移动到另一个集合sinter &lt;key1&gt;&lt;key2&gt;\t\t\t # 返回两个集合的交集元素sunion &lt;key1&gt;&lt;key2&gt;\t\t\t # 返回两个集合的并集元素sdiff &lt;key1&gt;&lt;key2&gt;\t\t\t # 返回两个集合的差集元素（key1 中的，不包含 key2 中的）\n\nSet的内部数据结构\nSet 数据结构是字典，字典是用哈希表实现的。\nd. 哈希 HashRedis hash 是一个键值对集合。\nRedis hash 是一个 String 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。\n注意 Redis的Hash类型和String类型的区别。\n\n\n常用命令:\n12345678hset &lt;key&gt;&lt;field&gt;&lt;value&gt;\t\t# 给 &lt;key&gt; 集合中的 &lt;field&gt; 键赋值 &lt;value&gt;hget &lt;key1&gt;&lt;field&gt;\t\t\t    # 从 &lt;key1&gt; 集合 &lt;field&gt; 取出 valuehmset &lt;key1&gt;&lt;field1&gt;&lt;value1&gt;&lt;field2&gt;&lt;value2&gt;...  # 批量设置 hash 的值hexists &lt;key1&gt;&lt;field&gt;\t\t\t# 查看哈希表 key 中，给定域 field 是否存在hkeys &lt;key&gt;\t\t\t\t# 列出该 hash 集合的所有 fieldhvals &lt;key&gt;\t\t\t\t# 列出该 hash 集合的所有 valuehincrby &lt;key&gt;&lt;field&gt;&lt;increment&gt;\t # 为哈希表 key 中的域 field 的值加上增量 1 -1hsetnx &lt;key&gt;&lt;field&gt;&lt;value&gt;\t\t # 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在\n\nHash数据结构:\nHash 类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。\n当 field-value 长度较短且个数较少时，使用 ziplist，否则使用 hashtable。\ne. 有序集合 ZsetRedis 有序集合 zset 与普通集合 set 非常相似，是一个没有重复元素的字符串集合。\n不同之处是 zset有序集合的每个成员都关联了一个评分（score）,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复的。\n因为元素是有序的，所以可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。\n访问有序集合的中间元素也是非常快的，因此能够使用有序集合作为一个没有重复成员的智能列表。\n常用命令:\n123456789zadd &lt;key&gt;&lt;score1&gt;&lt;value1&gt;&lt;score2&gt;&lt;value2&gt;…\t\t# 将一个或多个 member 元素及其 score 值加入到有序集 key 当中zrange &lt;key&gt;&lt;start&gt;&lt;stop&gt; [WITHSCORES] \t\t    # 返回有序集 key 中，下标在 &lt;start&gt;&lt;stop&gt; 之间的元素# 当带 WITHSCORES，可以让分数一起和值返回到结果集zrangebyscore key min max [withscores] [limit offset count]\t \t# 返回有序集 key 中，所有 score 值介于 min 和 max 之间（包括等于 min 或 max ）的成员。有序集成员按 score 值递增（从小到大）次序排列。zrevrangebyscore key max min [withscores] [limit offset count]   # 同上，改为从大到小排列zincrby &lt;key&gt;&lt;increment&gt;&lt;value&gt;\t\t\t# 为元素的 score 加上增量zrem &lt;key&gt;&lt;value&gt;\t\t\t\t\t   # 删除该集合下，指定值的元素zcount &lt;key&gt;&lt;min&gt;&lt;max&gt;\t\t\t\t    # 统计该集合，分数区间内的元素个数zrank &lt;key&gt;&lt;value&gt;\t\t\t\t\t   # 返回该值在集合中的排名，从 0 开始。\n\nZset内部结构:\nSortedSet（zset）是 Redis 提供的一个非常特别的数据结构，一方面它等价于 Java 的数据结构 Map&lt;String, Double&gt;，可以给每一个元素 value 赋予一个权重 score，另一方面它又类似于 TreeSet，内部的元素会按照权重 score 进行排序，可以得到每个元素的名次，还可以通过 score 的范围来获取元素的列表。\nzset 底层使用了两个数据结构\n\nhash，hash 的作用就是关联元素 value 和权重 score，保障元素 value 的唯一性，可以通过元素 value 找到相应的 score 值\n跳跃表，跳跃表的目的在于给元素 value 排序，根据 score 的范围获取元素列表\n\nf. BitmapsRedis 提供了 Bitmaps 这个数据类型 来实现位操作。\n\nBitmaps 本身不是一个数据类型,实际上是一个01字符串,但是它可以对这个字符串进行位操作。\nBitmaps 单独提供了一套指令,所以在Redis中使用Bitmaps和使用字符串方式不同, 可以把Bitmaps想象成一个以位为单位的数组,每个单位只能存储01,下标在Bitmaps中成为 偏移量。\n\n\n\n常用命令\n1234setbit &lt;key&gt; &lt;offset&gt; &lt;value&gt;\t\t# 给一个指定key的值得第offset位 赋值为value。getbit &lt;key&gt; &lt;offset&gt;\t\t\t    # 返回一个指定key的二进制信息bitcount &lt;key&gt; &lt;start&gt; &lt;offset&gt;\t\t# 返回一个指定key中位的值为1的个数(是以byte为单位不是bit)bitop &lt;operation&gt; &lt;destkey&gt; key1 key2  \t# 对key1 和key2 执行 operation 并将结果保存到 destkey\n\n主要用途\n​    主要用来存储大数据量但数据简单的操作,比如统计活跃用户量。\ng. HyperLogLogHyperLogLog是Redis的高级数据结构，它在做基数统计的时候非常有用，每个HyperLogLog的键可以计算接近 $2^{64}$ 不同元素的基数，而大小只需要12KB。\nHyperLogLog可以用很少的内存来存储集合的唯一元素。（每个HyperLogLog只有12K加上key本身的几个字节）\nHyperLogLog的结果并不精准，错误率大概在0.81%。\n常用操作\n123pfadd &lt;key&gt; &lt;element&gt;[element]  # 添加指定元素到Hyperloglog中pfcount &lt;key&gt;\t\t\t\t  # 统计key中包含的元素的个数 \tpfmerge &lt;destkey&gt; &lt;sourcekey&gt; [sourcekey] \t# 将两个或多个元素集合合并\n\n\n\n主要用途\n​    主要用来计算大量数据的基数。\nh. Geospatial​    Geo类型 是Geographic地理信息类型的缩写,该元素就是二维坐标,是地图上的经纬度。 Redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。\n常用命令\n123456geoadd key [NX|XX] [CH] longitude latitude member [longitude latitude member ...]# geoadd china:city 121.49 31.23 shanghai 添加一个位置信息geopos key member [member ...]\t\t# geopos china:city shanghai  获取一个城市的信息geodist key member1 member2 [m|km|ft|mi] # 获取两个位置之间的距离 [m|km|ft|mi] 来确定单位georadius key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] # 获取一个经纬度范围内的位置信息\n\n\n\n\n\n\n\n4. Redis 配置文件本机安装Redis时,文件的配置路径为 /etc/redis.conf\n如果使用docker由镜像生成redis容器,默认是没有配置文件的,需要自己在宿主机进行创建,然后进行配置文件挂载 /docker/redis/conf/redis.conf:/etc/redis/redis.conf \\。\n在配置文件中可以设置：\n\nUnits 单位，配置大小单位，开头定义了一些基本的度量单位，只支持 bytes，不支持 bit。大小写不敏感。\n\nINCLUDES 包含，多实例的情况可以把公用的配置文件提取出来。\n\nNETWORK 网络相关配置。\n\nbind 默认情况 bind=127.0.0.1 只能接受本机的访问请求。不写的情况下，无限制接受任何 ip 地址的访问。生产环境肯定要写你应用服务器的地址，服务器是需要远程访问的，所以需要将其注释掉。\n\nprotected-mode 如果开启了protected-mode，那么在没有设定 bind ip 且没有设密码的情况下，Redis 只允许接受本机的响应。\n\nport 端口号，默认 6379。\n\n\n\nGENERAL 通用。\n\ndaemonize 是否为后台进程，设置为 yes。\n\npidfile  存放 pid 文件的位置，每个实例会产生一个不同的 pid 文件。\n\nloglevel 指定日志记录级别，Redis 总共支持四个级别：debug、verbose、notice、warning，默认为 notice。\n\nlogfile 日志文件名称。\n\ndatabase 设定库的数量 默认16，默认数据库为 0，可以使用 SELECT &lt;dbid&gt; 命令在连接上指定数据库 id。\n\n\n\nSECURITY 安全。\n访问密码的查看、设置和取消。\n在命令中设置密码，只是临时的。重启 redis 服务器，密码就还原了。\n永久设置，需要在配置文件中进行设置。\n\nLIMITS  限制。\n\nmaxclients设置 redis 同时可以与多少个客户端进行连接。默认情况下为 10000 个客户端。\n如果达到了此限制，redis 则会拒绝新的连接请求，并且向这些连接请求方发出 max number of clients reached 以作回应。\n\nmaxmemory 建议必须设置，否则，将内存占满，造成服务器宕机。\n设置 redis 可以使用的内存量。一旦到达内存使用上限，redis 将会试图移除内部数据，移除规则可以通过 maxmemory-policy 来指定。\n如果 redis 无法根据移除规则来移除内存中的数据，或者设置了不允许移除，那么 redis 则会针对那些需要申请内存的指令返回错误信息，比如 SET、LPUSH 等。\n\nmaxmemory-policy\n\nvolatile-lru：使用 LRU 算法移除 key，只对设置了过期时间的键（最近最少使用）\n\nallkeys-lru：在所有集合 key 中，使用 LRU 算法移除 key。\n\n\n\n\n5. Redis的发布与订阅Redis 发布订阅（ pub&#x2F;sub ）是一种消息通信模式：发送者（ pub ）发送消息，订阅者（ sub ）接收消息。\nRedis 客户端可以订阅任意数量的频道。\n\n客户端可以订阅频道\n\n\n\n\n当给这个频道发布消息后，消息就会发送给订阅的客户端\n\n\n\n12subscribe channel \t\t # 订阅频道publish channel hello \t # 频道发送信息\n\n6. SpringBoot整合Redisa. 添加pom.xml 依赖\n123456789101112&lt;!-- redis --&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- spring2.X集成redis所需common-pool2--&gt;&lt;dependency&gt;  &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;  &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;  &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;\n\nb. 配置Redis\n12345678910111213141516#Redis服务器地址spring.redis.host= ip#Redis服务器连接端口spring.redis.port=6379#Redis数据库索引（默认为0）spring.redis.database= 0#连接超时时间（毫秒）spring.redis.timeout=1800000#连接池最大连接数（使用负值表示没有限制）spring.redis.lettuce.pool.max-active=20#最大阻塞等待时间(负数表示没限制)spring.redis.lettuce.pool.max-wait=-1#连接池中的最大空闲连接spring.redis.lettuce.pool.max-idle=5#连接池中的最小空闲连接spring.redis.lettuce.pool.min-idle=0\n\nc. Redis 配置类\n12345678910111213141516171819202122232425262728293031323334353637383940414243@EnableCaching@Configurationpublic class RedisConfig extends CachingConfigurerSupport &#123;    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123;        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();        RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer();        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(om);        template.setConnectionFactory(factory);\t\t\t\t// key序列化方式        template.setKeySerializer(redisSerializer);\t\t\t\t// value序列化        template.setValueSerializer(jackson2JsonRedisSerializer);\t\t\t\t// value hashmap序列化        template.setHashValueSerializer(jackson2JsonRedisSerializer);        return template;    &#125;    @Bean    public CacheManager cacheManager(RedisConnectionFactory factory) &#123;        RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer();        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\t\t\t\t// 解决查询缓存转换异常的问题        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(om);\t\t\t\t// 配置序列化（解决乱码的问题）,过期时间600秒        RedisCacheConfiguration config =           RedisCacheConfiguration.defaultCacheConfig()                .entryTtl(Duration.ofSeconds(600))      .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))                .disableCachingNullValues();        RedisCacheManager cacheManager = RedisCacheManager.builder(factory)                .cacheDefaults(config)                .build();        return cacheManager;    &#125;&#125;\n\n\n\n7. Redis事务Redis 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\nRedis 事务的主要作用就是串联多个命令防止别的命令插队。\n事务三特性\n\n单独的隔离操作\n事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n\n没有隔离级别的概念\n队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行。\n\n不保证原子性\n事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚\n\n\na. Multi、Exec、Discard从输入 Multi 命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入 Exec 后，Redis 会将之前的命令队列中的命令依次执行。\n组队的过程中可以通过 Discard 来放弃组队。\n\n\n\n\n12345678910127.0.0.1:6379&gt; multi\t\t\t\t# 开启事务OK127.0.0.1:6379(TX)&gt; set key1 val1\t # 进入队列\tQUEUED127.0.0.1:6379(TX)&gt; set key2 val2\t # 进入队列QUEUED127.0.0.1:6379(TX)&gt; exec\t\t\t# 开始执行1) OK2) OK# 开始执行之前 使用discard命令可以中断排队\n\n组队中有命令错误，队列中所有命令都不会执行\n12345678127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; set a1 b1QUEUED127.0.0.1:6379(TX)&gt; set b(error) ERR wrong number of arguments for &#x27;set&#x27; command127.0.0.1:6379(TX)&gt; exec(error) EXECABORT Transaction discarded because of previous errors.\n\n组队中不报错，执行时报错,只有报错的命令会被取消。\n123456789127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; set vas sdadQUEUED127.0.0.1:6379(TX)&gt; incr vasQUEUED127.0.0.1:6379(TX)&gt; exec1) OK2) (error) ERR value is not an integer or out of range\n\n\n\nb. 事务冲突多个事务对同一数据进行操作时可能出现冲突。\n1. 悲观锁悲观锁（Pessimistic Lock），即每次去拿数据的时候都认为有其他线程会修改，所以每次在拿数据的时候都会上锁，这样其他线程想要拿到这个数据就会被 block 直到成功拿到锁。（效率低）\n一个事务执行时，其他对同一数据进行操作的事务都不能执行。\n2. 乐观锁乐观锁（Optimistic Lock），即每次去拿数据的时候都认为其他线程不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间有没有其他线程去更新这个数据，可以使用版本号等机制。\n乐观锁适用于多读的应用类型，这样可以提高吞吐量。\nRedis 就是利用这种 check-and-set 机制实现事务的。\n3. Watch、unwatch在执行 multi 之前，先执行 watch key1 [key2]，可以监视一个（或多个 ）key 。如果在事务执行之前这个 key 被其他命令所改动，那么事务将被打断。\n取消 WATCH 命令对所有 key 的监视。如果在执行 WATCH 命令之后，EXEC 命令或 DISCARD 命令先被执行，那么就不需要再执行 UNWATCH 。\n8. 持久化将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。\na. RDB(Redis DataBase)在指定的 时间间隔内 将内存汇总的数据集快照写入磁盘。 即 Snapshot 快照，恢复时是将快照文件直接读到内存里。\n备份过程\nRedis 会单独创建一个子进程（fork）来进行持久化。\n先将数据写入到一个临时文件中，待持久化过程完成后，再将这个临时文件内容覆盖到 dump.rdb。\n整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。\nRDB 的缺点是最后一次持久化后的数据可能丢失。\nFork子进程\n\n作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程\n在 Linux 程序中，fork() 会产生一个和父进程完全相同的子进程，但子进程在此后多会 exec 系统调用，出于效率考虑，Linux 中引入了 写时复制技术\n一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程\n\n和RDB有关的配置\n\n临时文件名设置。  在 redis.conf 中配置文件名称，默认为 dump.rdb。\n\n临时文件保存位置。  rdb 文件的保存路径可以修改。默认为 Redis 启动时命令行所在的目录下。\n\nstop-writes-on-bgsave-error   即当 redis 无法写入磁盘，关闭 redis 的写入操作。\n\nrdbcompression    持久化的文件是否进行压缩存储。\n\nrdbchecksum   完整性的检查，即数据是否完整性、准确性。\n\nsave   表示达到什么操作数时进行备份。\n1save 60 10000  # 表示 如果60s内 超过 10000个keys改变过,那么触发持久化\n\n优点\n\n适合大规模的数据恢复；\n对数据完整性和一致性要求不高更适合使用；\n节省磁盘空间；\n恢复速度快。\n\n缺点\n\nFork 的时候，内存中的数据被克隆了一份，大致 2 倍的膨胀性需要考虑；\n虽然 Redis 在 fork 时使用了**写时拷贝技术**，但是如果数据庞大时还是比较消耗性能；\n在备份周期在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改。\n\nRBD的备份过程\n​    只需要将 要备份的rdb文件拷贝到备份文件的默认目录下,启动redis即可自动将rdb文件恢复。\nb. AOF(Append Of File)以日志的形式来记录每个写操作（增量保存），将 Redis 执行过的所有写指令记录下来（读操作不记录）， 只许追加文件但不可以改写文件，Redis 启动之初会读取该文件重新构建数据。\n如果 Redis 重启就会根据日志文件（如果AOF文件和RDB文件都存在，优先恢复AOF）的内容将写指令从前到后执行一次以完成数据的恢复工作。\nAOF默认不开启。在配置文件中设置 appendonly yes 打开\n执行流程\n\n客户端的请求写命令会被 append 追加到 AOF 缓冲区内；\nAOF 缓冲区根据 AOF 持久化策略 [always,everysec,no] 将操作 sync 同步到磁盘的 AOF 文件中；\nAOF 文件大小超过重写策略或手动重写时，会对 AOF 文件 Rewrite 重写，压缩 AOF 文件容量；\nRedis 服务重启时，会重新 load 加载 AOF 文件中的写操作达到数据恢复的目的。\n\nAOF 和 RDB 同时开启时，系统默认读取 AOF 的数据（数据不会存在丢失）\n和AOF有关的配置\n\nappendfsync always  时钟同步，每次 Redis 的写入都会立刻记入日志；性能较差但数据完整性比较好。\nappendfsync everysec  每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。\nappendfsync no Redis 不主动进行同步，把同步时机交给操作系统。\nRewrite 压缩当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令 bgrewriteaof。\n\nAOF 修复\n当AOF文件出错时,可以使用 redis-check-aof--fix [文件名] 命令对AOF文件进行修复。\nAOF优势\n\n备份机制更稳健，丢失数据概率更低；\n可读的日志文本，通过操作 AOF 稳健，可以处理误操作。\n\nAOF缺点\n\n比起 RDB 占用更多的磁盘空间；\n恢复备份速度要慢；\n每次读写都同步的话，有一定的性能压力；\n存在个别 Bug，造成不能恢复。\n\nc. AOF和RDB的选择官方推荐两个都启用。\n如果对数据不敏感，可以选单独用 RDB。\n不建议单独用 AOF，因为可能会出现 Bug。\n如果只是做纯内存缓存，可以都不用。\n9. Redis 主从复制主机数据更新后根据配置和策略， 自动同步到备机的 master&#x2F;slaver 机制，Master 以写为主，Slaver 以读为主。\n\n\n主从复制的优势\n\n读写分离，性能扩展\n容灾快速恢复\n一主多从！\n\na. 模拟一主两从复制我自己通过Docker模拟实现。\n\n为每个redis容器创建自己的redis.conf文件\n\n先创建一个公用的redis.conf\n12345678# daemonize yesdir /datalogfile /data/redis.logprotected-mode no#注释掉，可以远程访问#bind 127.0.0.1#开启AOFappendonly no\n\n然后分别创建 redis6370.conf redis6371.conf redis6372.conf,写入对应的配置信息。\n1234include /redis-cluster/redis.confpidfile /var/run/redis_6370.pidport 6370dbfilename dump6370.rdb\n\n\n启动三个Redis容器，加载对应的conf文件\n\ndocker run -itd -p 6370:6379 -v /home/redis/redis.conf:/redis-cluster/redis6370.conf -v /home/redis/data/:/data --name redis6370 -e &quot;TZ=Asia/Shanghai&quot; redis  /redis-cluster/redis6370.conf\n123- ```sh  docker run -itd -p 6371:6379 -v /home/redis/redis.conf:/redis-cluster/redis6371.conf -v /home/redis/data/:/data --name redis6371 -e &quot;TZ=Asia/Shanghai&quot; redis  /redis-cluster/redis6371.conf\n\n\n&#96;&#96;&#96;shdocker run -itd -p 6372:6379 -v &#x2F;home&#x2F;redis&#x2F;redis.conf:&#x2F;redis-cluster&#x2F;redis6372.conf -v &#x2F;home&#x2F;redis&#x2F;data&#x2F;:&#x2F;data –name redis6372 -e “TZ&#x3D;Asia&#x2F;Shanghai” redis  &#x2F;redis-cluster&#x2F;redis6372.conf\n12345678910111213141516173. 随便进入一个redis进程,查看主从信息,发现三个都是主节点   ```sh   127.0.0.1:6379&gt; info replication   # Replication   role:master\t\t\t# 主机   connected_slaves:0\t # 没有slave节点   master_failover_state:no-failover   master_replid:1215d3dd30318947c9fbb130adb781e5e250bac5   master_replid2:0000000000000000000000000000000000000000   master_repl_offset:0   second_repl_offset:-1   repl_backlog_active:0   repl_backlog_size:1048576   repl_backlog_first_byte_offset:0   repl_backlog_histlen:0\n\n\n配置主从关系\n1slaveof [IP] [Port] # 将当前redis服务 作为从机备份到 [ip]:[port]\n\n由于此处使用的是docker,所以得先查看主机的docker的IP地址\n123456789101112131415161718docker inspect [容器名 redis6370]&quot;Networks&quot;: &#123;    &quot;bridge&quot;: &#123;        &quot;IPAMConfig&quot;: null,        &quot;Links&quot;: null,        &quot;Aliases&quot;: null,        &quot;NetworkID&quot;: &quot;a4b86cbe5c82a4651588bb950df3cd42cd8391bffba939ac5fc43858d1f2be37&quot;,        &quot;EndpointID&quot;: &quot;052a96ffb53bdf74a7322adfceba70248f17394a9697951e6d78f21f5bf0b72f&quot;,        &quot;Gateway&quot;: &quot;172.17.0.1&quot;,        &quot;IPAddress&quot;: &quot;172.17.0.8&quot;,        &quot;IPPrefixLen&quot;: 16,        &quot;IPv6Gateway&quot;: &quot;&quot;,        &quot;GlobalIPv6Address&quot;: &quot;&quot;,        &quot;GlobalIPv6PrefixLen&quot;: 0,        &quot;MacAddress&quot;: &quot;02:42:ac:11:00:08&quot;,        &quot;DriverOpts&quot;: null    &#125;&#125;\n\n查看 主机6370 和 从机6371&#x2F;2 对应的信息\n1234567891011121314151617# 6371 和 6372 作为 6370的从机# 6370127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2   # 得到两个从服务器slave0:ip=172.17.0.10,port=6379,state=online,offset=602,lag=1slave1:ip=172.17.0.9,port=6379,state=online,offset=602,lag=1master_failover_state:no-failovermaster_replid:46570ab087353ccfb3b0314f18f2f2a3cfa6a31fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:602second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:602\n\n123456789101112131415161718192021222324# 6371/2127.0.0.1:6379&gt; info replication# Replicationrole:slave\t\t# 角色为从机master_host:172.17.0.8\t# 主机为6370master_port:6379master_link_status:upmaster_last_io_seconds_ago:3master_sync_in_progress:0slave_read_repl_offset:1050slave_repl_offset:1050slave_priority:100slave_read_only:1replica_announced:1connected_slaves:0master_failover_state:no-failovermaster_replid:46570ab087353ccfb3b0314f18f2f2a3cfa6a31fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:1050second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:547repl_backlog_histlen:504\n\n在从机上写数据会报错\n123# 6371127.0.0.1:6379&gt; set k1 a(error) READONLY You can&#x27;t write against a read only replica.\n\n\n\nb. 主从复制原理\nslave 启动成功连接到 master 后会发送一个 sync 命令（同步命令）。\nmaster 接到命令启动后台的存盘进程，对数据进行持久化操作，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master 将传送整个数据文件（rdb）到 slave，以完成一次完全同步。\n当主服务进行写操作后，和从服务器进行数据同步。\n全量复制：而 slave 服务在接收到数据库文件数据后，将其存盘并加载到内存中。\n增量复制：master 继续将新的所有收集到的修改命令依次传给 slave，完成同步。\n只要是重新连接 master，一次完全同步（全量复制）将被自动执行。\n\nc. 主从复制常用方式1. 一主两仆主机为6370 从机 6371和6372;两个从机平等的作为一个主机的从机。\n从机挂掉\n当从机6371挂掉,重启后,6371不再作为6370的主机,而是作为新的master\n当再次把6380作为6379的从机加入后，从机 会把数据从头到尾复制。\n主机挂掉 \n6371和6372仍然是6370的从机，不会做任何事；当6370重启后，既然是主服务器。\n2. 薪火相传\n\n上一个 slave 可以是下一个 slave 的 master，slave 同样可以接收其他 slave的连接和同步请求，那么该 slave 作为了链条中下一个的 master，可以有效减轻 master 的写压力，去中心化降低风险。\n中途变更转向：会清除之前的数据，重新建立拷贝最新的。\n当某个 slave 宕机，后面的 slave 都没法备份。\n即当主机挂掉，从机还是从机，但是无法继续写数据。\n3. 反客为主 当一个 master 宕机后，后面的 slave 可以立刻升为 master，其后面的 slave 不用做任何修改。手动完成。\n1slaveof no one\n\n\n\nd. 哨兵模式哨兵模式自动实现主从切换，而上面的反客为主需要手动完成。\n能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。\n当主机宕机后,会在从机中选举新的主机\n选举规则\n\n根据优先级别，slave-priority&#x2F;replica-priority，优先选择优先级靠前的。\n\n\n根据偏移量，优先选择偏移量大的。\n\n根据 runid，优先选择最小的服务。\n\n\n复制延时\n由于所有的写操作都是先在 master 上操作，然后同步更新到 slave 上，所以从 master 同步到 slave 从机有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave 机器数量的增加也会使这个问题更加严重。\n设置哨兵模式的方法\n\n创建 sentinel.conf 文件\n\n1/opt/etc/sentinel.conf\n\n\n配置哨兵\n\n123sentinel monitor mymaster 172.16.88.168 6379 1# mymaster：监控对象起的服务器名称# 1：至少有多少个哨兵同意迁移的数量。 \n\n\n启动哨兵\n\n1redis-sentinel  /opt/etc/sentinel.conf \n\n\n\n10. Redis 集群集群需要解决的问题\n容量不够，redis 如何进行扩容？\n并发写操作， redis 如何分摊？\n主从模式，薪火相传模式，主机宕机，导致 ip 地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。\n解决方案\n\n代理主机\n\n\n无中心化集群配置\n\n\n\n\n\n\nRedis 集群实现了对 Redis 的水平扩容，即启动 N 个 Redis 节点，将整个数据库分布存储在这 N 个节点中，每个节点存储总数据的 1&#x2F;N 。\nRedis 集群通过分区（partition）来提供一定程度的可用性（availability），即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。\na. 搭建Redis集群搭建一个由三对主从服务器组成的redis集群,共六个redis服务器。\n\n创建六个redis服务的conf文件\n六个服务的主从端口号为：6370-6380 6371-6381 6372-6382\n123456789[root@VM-4-9-centos redis-cluster]# lltotal 32-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6370.conf-rw-r--r-- 1 root root 183 Mar 23 19:38 redis6371.conf-rw-r--r-- 1 root root 183 Mar 23 19:38 redis6372.conf-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6380.conf-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6381.conf-rw-r--r-- 1 root root 183 Mar 23 19:37 redis6382.conf-rw-r--r-- 1 root root 142 Mar 23 19:27 redis.conf\n\n配置文件内容为:\n1234567include /redis-cluster/redis.confpidfile /var/run/redis_6370.pidport 6370dbfilename dump6370.rdbcluster-enabled yescluster-config-file node6370.confcluster-node-timeout 15000\n\n启动六个redis服务器\n启动命令为:\n12# 此处以6380为例,其他以此类推docker run -itd -p 6380:6379 -v /home/redis/redis.conf:/redis-cluster/redis6380.conf -v /home/redis/data/:/data --name redis6380 -e &quot;TZ=Asia/Shanghai&quot; redis  /redis-cluster/redis6380.conf\n\n12345678[root@VM-4-9-centos redis-cluster]# docker psCONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS                                                  NAMESc0ddd1a17009   redis         &quot;docker-entrypoint.s…&quot;   4 seconds ago    Up 4 seconds    0.0.0.0:6380-&gt;6379/tcp, :::6380-&gt;6379/tcp              redis6380677f6d098415   redis         &quot;docker-entrypoint.s…&quot;   29 seconds ago   Up 28 seconds   0.0.0.0:6381-&gt;6379/tcp, :::6381-&gt;6379/tcp              redis6381cf71e9f7f3cf   redis         &quot;docker-entrypoint.s…&quot;   2 minutes ago    Up 2 minutes    0.0.0.0:6382-&gt;6379/tcp, :::6382-&gt;6379/tcp              redis63827657bb60a3ec   redis         &quot;docker-entrypoint.s…&quot;   2 minutes ago    Up 2 minutes    0.0.0.0:6372-&gt;6379/tcp, :::6372-&gt;6379/tcp              redis6372e48e4d898b90   redis         &quot;docker-entrypoint.s…&quot;   3 minutes ago    Up 3 minutes    0.0.0.0:6371-&gt;6379/tcp, :::6371-&gt;6379/tcp              redis637179232aef9947   redis         &quot;docker-entrypoint.s…&quot;   4 minutes ago    Up 4 minutes    0.0.0.0:6370-&gt;6379/tcp, :::6370-&gt;6379/tcp              redis6370\n\n查看docker中,各个redis服务的IP地址,记录下来\n123456docker inspect redis6370  \t# 172.17.0.8docker inspect redis6371  \t# 172.17.0.9docker inspect redis6372  \t# 172.17.0.10docker inspect redis6380  \t# 172.17.0.12docker inspect redis6381  \t# 172.17.0.7docker inspect redis6382  \t# 172.17.0.11\n\n进入某一容器中,使用集群搭建命令\n12# 执行redis-cli --cluster create --cluster-replicas 1 172.17.0.8:6370 172.17.0.9:6371 172.16.88.168:6381 172.16.88.168:6389 172.16.88.168:6390 172.16.88.168:6391\n\nredis cluster 如何分配这六个节点?\n一个集群至少要有三个主节点。\n选项 --cluster-replicas 1，表示希望为集群中的每个主节点创建一个从节点。\n分配原则 尽量保证每个主数据库运行在不同的 IP 地址，每个从库和主库不在一个 IP 地址上。\n\n\n\n\n*什么是 slots？*\n一个 Redis 集群包含 16384 个插槽（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个。\n集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。\n集群中的每个节点负责处理一部分插槽。 例如， 如果一个集群可以有主节点， 其中：\n\n节点 A 负责处理 0 号至 5460 号插槽。\n节点 B 负责处理 5461 号至 10922 号插槽。\n节点 C 负责处理 10923 号至 16383 号插槽。\n\n如何在集群中录入值？\n在 redis-cli 每次录入、查询键值，redis 都会计算出该 key 应该送往的插槽，如果不是该客户端对应服务器的插槽，redis 会报错，并告知应前往的 redis 实例地址和端口。\nredis-cli 客户端提供了 –c 参数实现自动重定向。\n例如 redis-cli -c –p 6379 登入后，再录入、查询键值对可以自动重定向。\n如何查询集群中的值？\n每个主机只能查询自己范围内部的插槽。\ncluster keyslot &lt;key&gt;：查询某个 key 的 slot。\ncluster countkeysinslot &lt;slot&gt;：查询某个 slot 是否有值。\nCLUSTER GETKEYSINSLOT &lt;slot&gt;&lt;count&gt;：返回 count 个 slot 槽中的键。\n故障恢复\n如果主节点下线？从节点能否自动升为主节点？注意：15 秒超时。\n\n当 6379 挂掉后，6389 成为新的主机。\n\n主节点恢复后，主从关系会如何？主节点回来变成从机。\n\n当 6379 重启后，6379 成为 6389 的从机。\n\n如果所有某一段插槽的主从节点都宕掉，redis 服务是否还能继续?\n\n如果某一段插槽的主从都挂掉，而 cluster-require-full-coverage&#x3D;yes，那么 ，整个集群都挂掉。\n如果某一段插槽的主从都挂掉，而 cluster-require-full-coverage&#x3D;no，那么，该插槽数据全都不能使用，也无法存储。\n\n1redis.conf` 中的参数 `cluster-require-full-coverage\n\n\n\nb. 集群优点\n实现扩容；\n分摊压力；\n无中心配置相对简单。\n\nc. 集群缺点\n多键操作是不被支持的；\n多键的 Redis 事务是不被支持的。lua 脚本不被支持；\n由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大\n\n11. Redis 应用问题a. 缓存穿透\n\n现象\nkey 对应的数据在数据源并不存在，每次针对此 key 的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。\n比如用一个不存在的用户 id 获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。\n造成：\n\n应用服务器压力变大。\nredis 命中率下降 –&gt; 一直查询数据库 。\n\n如何解决\n\n对空值缓存\n如果一个查询返回的数据为空（不管是数据是否不存在），仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。\n\n设置可访问的名单（白名单）：\n使用 bitmaps 类型定义一个可以访问的名单，名单 id 作为 bitmaps 的偏移量，每次访问和 bitmap 里面的 id 进行比较，如果访问 id 不在 bitmaps 里面，进行拦截，则不允许访问。\n\n采用布隆过滤器\n布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量（位图）和一系列随机映射函数（哈希函数）。\n布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。\n将所有可能存在的数据哈希到一个足够大的 bitmaps 中，一个一定不存在的数据会被这个 bitmaps 拦截掉，从而避免了对底层存储系统的查询压力。\n\n进行实时监控\n当发现 Redis 的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。\n\n\nb.  缓存击穿\n\nkey 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。\n\n数据库访问压力瞬间增大。\nredis 中没有出现大量 key 过期，redis 正常运行。\n某个经常访问的 key 过期，突然有大量访问这个数据\n\n如何解决\n\n预先设置热门数据\n在 redis 高峰访问之前，把一些热门数据提前存入到 redis 里面,加大这些热门数据 key 的时长。\n\n实时调整\n现场监控哪些数据热门，实时调整 key 的过期时长。\n\n使用锁\n效率会降低\n\n\nc. 缓存雪崩\n\nkey 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。\n缓存雪崩与缓存击穿的区别在于这里针对很多 key 缓存，前者则是某一个 key。\n\n数据库压力变大。\n即极少的时间段，查询大量 key 的集中过期情况。\n\n如何解决\n\n构建多级缓存架构****\nnginx 缓存 + redis 缓存 + 其他缓存（ehcache等）\n\n使用锁或队列：\n用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况。\n\n设置过期标志更新缓存：\n记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。\n\n将缓存失效时间分散开：\n比如我们可以在原有的失效时间基础上增加一个随机值，比如 1～5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n\n\n12. 分布式锁​    随着计算机系统规模的发展,分布式系统越来越多的被应用到商业中。由于分布式系统分布在不同的机器上，将使原有的单机情况下的并发控制锁策略失效，单冲的Java API 并没有提供分布式锁的能力，为了解决这个问题，就需要一种垮JVM的互斥机制来控制共享资源的访问。\n主流的分布式锁解决方案\n\n基于数据库实现分布式锁\n基于缓存实现分布式锁，性能最高\n基于Zookeeper，可靠性最高\n\na. 基于Redis的分布式锁实现1. setnxredis中可以使用 setnx 来设置一个带锁的键值对,加锁期间其他的人无法进行修改。\n为了防止一直加锁,可以使用expire设置过期时间。del来删除锁\n为了防止设置过期时间的时候就出现异常,导致设置失败,可以在set的同时进行加锁,并同时设置过期时间。\n12345678910111213141516171819202122232425262728293031127.0.0.1:6379&gt; setnx user k1  # 设置带锁的user(integer) 1127.0.0.1:6379&gt; setnx user k2  # 锁没释放,无法再次设置\t(integer) 0127.0.0.1:6379&gt; setnx user k3(integer) 0127.0.0.1:6379&gt; del user\t   # 删除锁\t(integer) 1127.0.0.1:6379&gt; setnx user k3   # 就可以再次设置\t(integer) 1127.0.0.1:6379&gt; expire user 10\t# 可以设置过期时间(integer) 1127.0.0.1:6379&gt; ttl user(integer) 7127.0.0.1:6379&gt; ttl user(integer) 6127.0.0.1:6379&gt; ttl user(integer) 1127.0.0.1:6379&gt; ttl user \t# 过期(integer) -2# 为了防止设置过期时间的时候就出现异常,导致设置失败,可以在set的同时进行加锁,并设置过期时间127.0.0.1:6379&gt; set k2 v2 nx ex 12OK127.0.0.1:6379&gt; get k2&quot;v2&quot;127.0.0.1:6379&gt; ttl k2(integer) 6127.0.0.1:6379&gt; ttl k2(integer) 4127.0.0.1:6379&gt; ttl k2(integer) 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Redis","date":"2022-04-07T05:26:46.000Z","categories_index":"","tags_index":"分布式缓存,Redis","author_index":"张 凡"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post1$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server1$ hexo server\n\nMore info: Server\nGenerate static files1$ hexo generate\n\nMore info: Generating\nDeploy to remote sites1$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-04-07T02:07:52.961Z","categories_index":"","tags_index":"","author_index":"张 凡"}]